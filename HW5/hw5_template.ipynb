{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(optional)"
      ],
      "metadata": {
        "id": "4hiUrTp2g31d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "02ixxyXJQRNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3b0e99-552e-4c90-f665-26e069c5be00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.chdir('...')"
      ],
      "metadata": {
        "id": "cwb1U7JElJPa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW5: Brain signal classification**\n",
        "In *HW 5*, you need to finish:\n",
        "\n",
        "1.  Model Implementation Part: Implement LSTM and EEGNet models to predict the label of each samples.\n",
        "\n",
        "2.  Model Competition Part: Implementing a model to reach better accuracy performance."
      ],
      "metadata": {
        "id": "CQX9eCfIcRAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the packages you need here\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "#\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n"
      ],
      "metadata": {
        "id": "BKJDTLRvQrnY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/data.npz')\n",
        "label = np.load('/content/drive/MyDrive/label.npz')\n"
      ],
      "metadata": {
        "id": "ZQQylnWHQ4yy"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data['X_train']\n",
        "X_val = data['X_val']\n",
        "X_test = data['X_test']\n",
        "\n",
        "Y_train = label['Y_train']\n",
        "Y_val = label['Y_val']"
      ],
      "metadata": {
        "id": "3Ype-nIkQ-bf"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "id": "xjPvKG_im7mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f1dbc6-15e5-4468-e8b8-3640807d40c3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((604, 22, 200), (152, 22, 200), (190, 22, 200))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape, Y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7apA2_-lBjF",
        "outputId": "09b1da1d-01b7-4df7-dd8b-bd294602951f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((604, 1), (152, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Implementation Part"
      ],
      "metadata": {
        "id": "diYYd3e7eopi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "97BpHWOAevWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainy = to_categorical(Y_train)\n",
        "valy = to_categorical(Y_val)\n",
        "print(trainy.shape, valy.shape)\n",
        "print(trainy[1],Y_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6-8RdF3JXLb",
        "outputId": "ef73c49f-09eb-4f98-8976-621ee5fddd66"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(604, 6) (152, 6)\n",
            "[1. 0. 0. 0. 0. 0.] [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model here:\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        " verbose, epochs, batch_size = 0, 15, 64\n",
        " n_timesteps, n_features, n_outputs = trainX.shape[2], trainX.shape[1], trainy.shape[1]\n",
        " model = Sequential()\n",
        " model.add(LSTM(100, input_shape=(n_features,n_timesteps)))\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Dense(100, activation='relu'))\n",
        " model.add(Dense(n_outputs, activation='softmax'))\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " # fit network\n",
        " a=model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        " # evaluate model\n",
        " _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        " return accuracy,model,a"
      ],
      "metadata": {
        "id": "xxFGe6YRe7qn"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        " print(scores)\n",
        " m, s = np.mean(scores), np.std(scores)\n",
        " print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        " \n",
        "# # run an experiment\n",
        "# def run_experiment(repeats=10):\n",
        "#  # load data\n",
        "#  trainX, trainy, testX, testy = load_dataset()\n",
        "#  # repeat experiment\n",
        "#  scores = list()\n",
        "#  for r in range(repeats):\n",
        "#  score = evaluate_model(trainX, trainy, testX, testy)\n",
        "#  score = score * 100.0\n",
        "#  print('>#%d: %.3f' % (r+1, score))\n",
        "#  scores.append(score)\n",
        "#  # summarize results\n",
        "#  summarize_results(scores)\n",
        " "
      ],
      "metadata": {
        "id": "r9vTQvXnPyQt"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = list()\n",
        "\n",
        "max_s,model,a=evaluate_model(X_train, trainy, X_val, valy)\n",
        "for r in range(10):\n",
        "  score,m,a = evaluate_model(X_train, trainy, X_val, valy)\n",
        "  score = score * 100.0\n",
        "  if score>max_s:\n",
        "    max_s=score\n",
        "    model=m\n",
        "    print(\"取代\")\n",
        "  print('>#%d: %.3f' % (r+1, score))\n",
        "  scores.append(score)\n",
        "# summarize results\n",
        "summarize_results(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4rwtl2P52K",
        "outputId": "13f8d66a-d7af-4fa5-b71d-dae631b28787"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "取代\n",
            ">#1: 69.737\n",
            "取代\n",
            ">#2: 76.316\n",
            ">#3: 70.395\n",
            ">#4: 73.026\n",
            ">#5: 73.026\n",
            ">#6: 73.684\n",
            ">#7: 76.316\n",
            ">#8: 73.684\n",
            "取代\n",
            ">#9: 78.947\n",
            ">#10: 73.026\n",
            "[69.73684430122375, 76.31579041481018, 70.3947365283966, 73.02631735801697, 73.02631735801697, 73.68420958518982, 76.31579041481018, 73.68420958518982, 78.94737124443054, 73.02631735801697]\n",
            "Accuracy: 73.816% (+/-2.628)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(a.history['loss'])\n",
        "# plt.plot(a.history['val_loss'])\n",
        "plt.title('lstm loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "6rfE4hsX2fJ3",
        "outputId": "5ad363e5-f8fb-42c7-d252-34833a520ed7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWTQ7rjb8QAj",
        "outputId": "65d61b86-db8c-46b5-8855-5bafdbdc383d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_26 (LSTM)              (None, 100)               120400    \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131,106\n",
            "Trainable params: 131,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans_test=model.predict(X_test)\n",
        "print(ans_test.shape)\n",
        "ans=[]\n",
        "for i in ans_test:\n",
        "  ans.append(np.argmax(i))\n",
        "\n",
        "ans=np.array(ans).reshape(190,1).astype(int)\n",
        "print(ans[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThJ7Er1HSNAa",
        "outputId": "57c23a5a-9f58-46d0-8b28-9e82859e9c77"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 12ms/step\n",
            "(190, 6)\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = \"...\"\n",
        "assert(ans.shape == (190, 1))\n",
        "np.savetxt('lstm_output.csv', ans, fmt='%i',delimiter=\",\")"
      ],
      "metadata": {
        "id": "sIXH_6BHjm6w"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EEGNet"
      ],
      "metadata": {
        "id": "xSGZPbDHrfOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#导入需要的库\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SpatialDropout2D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Input, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "def EEGNet(nb_classes, Chans = 22, Samples = 200,\n",
        "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
        "    \n",
        "    if dropoutType == 'SpatialDropout2D':\n",
        "        dropoutType = SpatialDropout2D\n",
        "    elif dropoutType == 'Dropout':\n",
        "        dropoutType = Dropout\n",
        "    else:\n",
        "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                         'or Dropout, passed as a string.')\n",
        "    \n",
        "    input1 = Input(shape = (Chans, Samples, 1))\n",
        "    print(\"input shape\", input1.shape, Chans, Samples, kernLength)\n",
        "    ##################################################################\n",
        "    block1 = Conv2D(F1, (1, kernLength), padding = 'same',\n",
        "                                   input_shape = (Chans, Samples, 1),\n",
        "                                   use_bias = False)(input1)\n",
        "    block1 = BatchNormalization()(block1)\n",
        "    block1 = DepthwiseConv2D((Chans, 1), use_bias = False,\n",
        "                                   depth_multiplier = D,\n",
        "                                   depthwise_constraint = max_norm(1.))(block1)\n",
        "    block1 = BatchNormalization()(block1)\n",
        "    block1 = Activation('elu')(block1)\n",
        "    block1 = AveragePooling2D((1, 4))(block1)\n",
        "    block1 = dropoutType(dropoutRate)(block1)\n",
        "\n",
        "    block2 = SeparableConv2D(F2, (1, 16),\n",
        "                                   use_bias = False, padding = 'same')(block1)\n",
        "    block2 = BatchNormalization()(block2)\n",
        "    block2 = Activation('elu')(block2)\n",
        "    block2 = AveragePooling2D((1, 8))(block2)\n",
        "    block2 = dropoutType(dropoutRate)(block2)\n",
        "    flatten = Flatten(name = 'flatten')(block2)\n",
        "    \n",
        "    dense = Dense(nb_classes, name = 'dense',\n",
        "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "    softmax = Activation('softmax', name = 'softmax')(dense)\n",
        "\n",
        "    return Model(inputs=input1, outputs=softmax)"
      ],
      "metadata": {
        "id": "2X6JXeQefdRS"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nX_train = X_train.reshape(X_train.shape[0], 22, 200, 1)\n",
        "nX_val = X_val.reshape(X_val.shape[0], 22, 200, 1)\n",
        "nX_test = X_test.reshape(X_test.shape[0], 22, 200, 1)\n",
        "\n",
        "print(nX_train.shape,nX_val.shape,nX_test.shape)\n",
        "\n",
        "nY_train = np_utils.to_categorical(Y_train )\n",
        "nY_val = np_utils.to_categorical(Y_val)\n",
        "print(nY_train.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI-X_AsyHX9d",
        "outputId": "0e2681f2-1b7e-499b-eb69-89c366b443a6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(604, 22, 200, 1) (152, 22, 200, 1) (190, 22, 200, 1)\n",
            "(604, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EEGNet(nb_classes = 6, Chans = nX_train.shape[1], Samples = nX_train.shape[2],\n",
        "               dropoutRate = 0.5, kernLength = 32, F1 = 8, D = 2, F2 = 16,\n",
        "               dropoutType = 'Dropout')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZV5Qk2aiF0m",
        "outputId": "a15eadc6-47af-4b86-9097-9b130c84ab43"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape (None, 22, 200, 1) 22 200 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# count number of parameters in the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFo7ACvwlXeh",
        "outputId": "e53b4eb7-70b4-4033-e8af-415e244e37b3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 22, 200, 1)]      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 200, 8)        256       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 22, 200, 8)       32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_1 (Depthwi  (None, 1, 200, 16)       352       \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 1, 200, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1, 200, 16)        0         \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 1, 50, 16)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 1, 50, 16)         0         \n",
            "                                                                 \n",
            " separable_conv2d_1 (Separab  (None, 1, 50, 16)        512       \n",
            " leConv2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 1, 50, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 50, 16)         0         \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 1, 6, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 1, 6, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 96)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 582       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,862\n",
            "Trainable params: 1,782\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fittedModel = model.fit(nX_train, nY_train, batch_size=16, epochs=300,\n",
        "                        verbose=2, validation_data=(nX_val, nY_val),\n",
        "                        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klT8cm0dlkAk",
        "outputId": "f6732f21-c76d-4856-981b-4f3f9b45a8a6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "38/38 - 3s - loss: 1.6824 - accuracy: 0.3692 - val_loss: 1.6350 - val_accuracy: 0.6513 - 3s/epoch - 84ms/step\n",
            "Epoch 2/300\n",
            "38/38 - 2s - loss: 1.3603 - accuracy: 0.6556 - val_loss: 1.4249 - val_accuracy: 0.8618 - 2s/epoch - 59ms/step\n",
            "Epoch 3/300\n",
            "38/38 - 2s - loss: 1.0867 - accuracy: 0.7417 - val_loss: 1.2345 - val_accuracy: 0.8750 - 2s/epoch - 59ms/step\n",
            "Epoch 4/300\n",
            "38/38 - 2s - loss: 0.9507 - accuracy: 0.7947 - val_loss: 1.1006 - val_accuracy: 0.8882 - 2s/epoch - 59ms/step\n",
            "Epoch 5/300\n",
            "38/38 - 2s - loss: 0.8866 - accuracy: 0.7930 - val_loss: 1.0084 - val_accuracy: 0.8816 - 2s/epoch - 58ms/step\n",
            "Epoch 6/300\n",
            "38/38 - 2s - loss: 0.8408 - accuracy: 0.8195 - val_loss: 0.9232 - val_accuracy: 0.8882 - 2s/epoch - 58ms/step\n",
            "Epoch 7/300\n",
            "38/38 - 2s - loss: 0.7967 - accuracy: 0.8278 - val_loss: 0.8541 - val_accuracy: 0.9013 - 2s/epoch - 60ms/step\n",
            "Epoch 8/300\n",
            "38/38 - 2s - loss: 0.7657 - accuracy: 0.8576 - val_loss: 0.8169 - val_accuracy: 0.9013 - 2s/epoch - 58ms/step\n",
            "Epoch 9/300\n",
            "38/38 - 2s - loss: 0.7578 - accuracy: 0.8543 - val_loss: 0.7508 - val_accuracy: 0.9145 - 2s/epoch - 59ms/step\n",
            "Epoch 10/300\n",
            "38/38 - 2s - loss: 0.7123 - accuracy: 0.8825 - val_loss: 0.7115 - val_accuracy: 0.9145 - 2s/epoch - 58ms/step\n",
            "Epoch 11/300\n",
            "38/38 - 3s - loss: 0.6924 - accuracy: 0.8659 - val_loss: 0.6670 - val_accuracy: 0.9276 - 3s/epoch - 70ms/step\n",
            "Epoch 12/300\n",
            "38/38 - 4s - loss: 0.6588 - accuracy: 0.8791 - val_loss: 0.6366 - val_accuracy: 0.9408 - 4s/epoch - 97ms/step\n",
            "Epoch 13/300\n",
            "38/38 - 2s - loss: 0.6358 - accuracy: 0.9073 - val_loss: 0.6069 - val_accuracy: 0.9342 - 2s/epoch - 59ms/step\n",
            "Epoch 14/300\n",
            "38/38 - 2s - loss: 0.6110 - accuracy: 0.8924 - val_loss: 0.5952 - val_accuracy: 0.9474 - 2s/epoch - 60ms/step\n",
            "Epoch 15/300\n",
            "38/38 - 2s - loss: 0.6066 - accuracy: 0.8957 - val_loss: 0.5465 - val_accuracy: 0.9737 - 2s/epoch - 60ms/step\n",
            "Epoch 16/300\n",
            "38/38 - 2s - loss: 0.5630 - accuracy: 0.9421 - val_loss: 0.5576 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 17/300\n",
            "38/38 - 2s - loss: 0.5634 - accuracy: 0.9123 - val_loss: 0.5177 - val_accuracy: 0.9737 - 2s/epoch - 58ms/step\n",
            "Epoch 18/300\n",
            "38/38 - 2s - loss: 0.5312 - accuracy: 0.9288 - val_loss: 0.4723 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 19/300\n",
            "38/38 - 2s - loss: 0.5337 - accuracy: 0.9222 - val_loss: 0.4503 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 20/300\n",
            "38/38 - 2s - loss: 0.5088 - accuracy: 0.9371 - val_loss: 0.4309 - val_accuracy: 0.9803 - 2s/epoch - 61ms/step\n",
            "Epoch 21/300\n",
            "38/38 - 2s - loss: 0.4883 - accuracy: 0.9437 - val_loss: 0.4171 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 22/300\n",
            "38/38 - 2s - loss: 0.4662 - accuracy: 0.9503 - val_loss: 0.4148 - val_accuracy: 0.9803 - 2s/epoch - 60ms/step\n",
            "Epoch 23/300\n",
            "38/38 - 2s - loss: 0.4603 - accuracy: 0.9520 - val_loss: 0.3983 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 24/300\n",
            "38/38 - 2s - loss: 0.4446 - accuracy: 0.9536 - val_loss: 0.3744 - val_accuracy: 0.9737 - 2s/epoch - 58ms/step\n",
            "Epoch 25/300\n",
            "38/38 - 2s - loss: 0.4254 - accuracy: 0.9570 - val_loss: 0.3826 - val_accuracy: 0.9803 - 2s/epoch - 60ms/step\n",
            "Epoch 26/300\n",
            "38/38 - 2s - loss: 0.4463 - accuracy: 0.9371 - val_loss: 0.3671 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 27/300\n",
            "38/38 - 2s - loss: 0.4402 - accuracy: 0.9156 - val_loss: 0.3220 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 28/300\n",
            "38/38 - 2s - loss: 0.4097 - accuracy: 0.9536 - val_loss: 0.3316 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 29/300\n",
            "38/38 - 2s - loss: 0.3964 - accuracy: 0.9652 - val_loss: 0.3120 - val_accuracy: 0.9737 - 2s/epoch - 58ms/step\n",
            "Epoch 30/300\n",
            "38/38 - 2s - loss: 0.3878 - accuracy: 0.9536 - val_loss: 0.3332 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 31/300\n",
            "38/38 - 2s - loss: 0.3956 - accuracy: 0.9487 - val_loss: 0.3211 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 32/300\n",
            "38/38 - 2s - loss: 0.3687 - accuracy: 0.9371 - val_loss: 0.3217 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 33/300\n",
            "38/38 - 2s - loss: 0.3771 - accuracy: 0.9404 - val_loss: 0.2881 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 34/300\n",
            "38/38 - 2s - loss: 0.3524 - accuracy: 0.9685 - val_loss: 0.2910 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 35/300\n",
            "38/38 - 2s - loss: 0.3423 - accuracy: 0.9652 - val_loss: 0.3043 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 36/300\n",
            "38/38 - 2s - loss: 0.3467 - accuracy: 0.9619 - val_loss: 0.3023 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 37/300\n",
            "38/38 - 2s - loss: 0.3303 - accuracy: 0.9768 - val_loss: 0.2966 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 38/300\n",
            "38/38 - 2s - loss: 0.3208 - accuracy: 0.9586 - val_loss: 0.2626 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 39/300\n",
            "38/38 - 2s - loss: 0.3339 - accuracy: 0.9437 - val_loss: 0.2770 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 40/300\n",
            "38/38 - 2s - loss: 0.3309 - accuracy: 0.9503 - val_loss: 0.2565 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 41/300\n",
            "38/38 - 2s - loss: 0.3277 - accuracy: 0.9553 - val_loss: 0.2491 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 42/300\n",
            "38/38 - 2s - loss: 0.3035 - accuracy: 0.9619 - val_loss: 0.2357 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 43/300\n",
            "38/38 - 2s - loss: 0.3057 - accuracy: 0.9553 - val_loss: 0.2363 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 44/300\n",
            "38/38 - 2s - loss: 0.3210 - accuracy: 0.9421 - val_loss: 0.2435 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 45/300\n",
            "38/38 - 2s - loss: 0.3017 - accuracy: 0.9636 - val_loss: 0.2205 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 46/300\n",
            "38/38 - 2s - loss: 0.2946 - accuracy: 0.9603 - val_loss: 0.2353 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 47/300\n",
            "38/38 - 2s - loss: 0.2984 - accuracy: 0.9619 - val_loss: 0.2330 - val_accuracy: 0.9737 - 2s/epoch - 58ms/step\n",
            "Epoch 48/300\n",
            "38/38 - 2s - loss: 0.2853 - accuracy: 0.9586 - val_loss: 0.2298 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 49/300\n",
            "38/38 - 2s - loss: 0.2898 - accuracy: 0.9454 - val_loss: 0.2251 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 50/300\n",
            "38/38 - 2s - loss: 0.2740 - accuracy: 0.9702 - val_loss: 0.2196 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 51/300\n",
            "38/38 - 2s - loss: 0.2635 - accuracy: 0.9702 - val_loss: 0.2178 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 52/300\n",
            "38/38 - 2s - loss: 0.2714 - accuracy: 0.9553 - val_loss: 0.2104 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 53/300\n",
            "38/38 - 2s - loss: 0.2598 - accuracy: 0.9669 - val_loss: 0.2112 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 54/300\n",
            "38/38 - 2s - loss: 0.2533 - accuracy: 0.9702 - val_loss: 0.1997 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 55/300\n",
            "38/38 - 2s - loss: 0.2685 - accuracy: 0.9536 - val_loss: 0.2052 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 56/300\n",
            "38/38 - 2s - loss: 0.2581 - accuracy: 0.9570 - val_loss: 0.1800 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 57/300\n",
            "38/38 - 3s - loss: 0.2374 - accuracy: 0.9702 - val_loss: 0.1958 - val_accuracy: 0.9803 - 3s/epoch - 88ms/step\n",
            "Epoch 58/300\n",
            "38/38 - 3s - loss: 0.2552 - accuracy: 0.9636 - val_loss: 0.1842 - val_accuracy: 0.9803 - 3s/epoch - 77ms/step\n",
            "Epoch 59/300\n",
            "38/38 - 2s - loss: 0.2536 - accuracy: 0.9586 - val_loss: 0.1920 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 60/300\n",
            "38/38 - 2s - loss: 0.2570 - accuracy: 0.9619 - val_loss: 0.1913 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 61/300\n",
            "38/38 - 2s - loss: 0.2555 - accuracy: 0.9603 - val_loss: 0.1677 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 62/300\n",
            "38/38 - 2s - loss: 0.2435 - accuracy: 0.9685 - val_loss: 0.1756 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 63/300\n",
            "38/38 - 2s - loss: 0.2585 - accuracy: 0.9652 - val_loss: 0.1825 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 64/300\n",
            "38/38 - 2s - loss: 0.2239 - accuracy: 0.9752 - val_loss: 0.1995 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 65/300\n",
            "38/38 - 2s - loss: 0.2288 - accuracy: 0.9669 - val_loss: 0.1946 - val_accuracy: 0.9737 - 2s/epoch - 59ms/step\n",
            "Epoch 66/300\n",
            "38/38 - 2s - loss: 0.2313 - accuracy: 0.9652 - val_loss: 0.1851 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 67/300\n",
            "38/38 - 2s - loss: 0.2356 - accuracy: 0.9570 - val_loss: 0.1651 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 68/300\n",
            "38/38 - 2s - loss: 0.2271 - accuracy: 0.9586 - val_loss: 0.1797 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 69/300\n",
            "38/38 - 2s - loss: 0.2359 - accuracy: 0.9586 - val_loss: 0.1691 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 70/300\n",
            "38/38 - 2s - loss: 0.2130 - accuracy: 0.9768 - val_loss: 0.1746 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 71/300\n",
            "38/38 - 2s - loss: 0.2070 - accuracy: 0.9851 - val_loss: 0.1624 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 72/300\n",
            "38/38 - 2s - loss: 0.2207 - accuracy: 0.9553 - val_loss: 0.1626 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 73/300\n",
            "38/38 - 2s - loss: 0.2149 - accuracy: 0.9735 - val_loss: 0.1596 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 74/300\n",
            "38/38 - 2s - loss: 0.2190 - accuracy: 0.9652 - val_loss: 0.1639 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 75/300\n",
            "38/38 - 2s - loss: 0.2144 - accuracy: 0.9652 - val_loss: 0.1490 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 76/300\n",
            "38/38 - 2s - loss: 0.2039 - accuracy: 0.9735 - val_loss: 0.1595 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 77/300\n",
            "38/38 - 2s - loss: 0.1949 - accuracy: 0.9818 - val_loss: 0.1562 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 78/300\n",
            "38/38 - 2s - loss: 0.1987 - accuracy: 0.9702 - val_loss: 0.1547 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 79/300\n",
            "38/38 - 2s - loss: 0.2141 - accuracy: 0.9652 - val_loss: 0.1507 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 80/300\n",
            "38/38 - 2s - loss: 0.2066 - accuracy: 0.9652 - val_loss: 0.1413 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 81/300\n",
            "38/38 - 2s - loss: 0.1928 - accuracy: 0.9752 - val_loss: 0.1344 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 82/300\n",
            "38/38 - 2s - loss: 0.1958 - accuracy: 0.9735 - val_loss: 0.1300 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 83/300\n",
            "38/38 - 2s - loss: 0.1975 - accuracy: 0.9669 - val_loss: 0.1431 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 84/300\n",
            "38/38 - 2s - loss: 0.1969 - accuracy: 0.9702 - val_loss: 0.1480 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 85/300\n",
            "38/38 - 2s - loss: 0.1845 - accuracy: 0.9785 - val_loss: 0.1428 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 86/300\n",
            "38/38 - 2s - loss: 0.1974 - accuracy: 0.9669 - val_loss: 0.1273 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 87/300\n",
            "38/38 - 2s - loss: 0.2055 - accuracy: 0.9735 - val_loss: 0.1563 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 88/300\n",
            "38/38 - 2s - loss: 0.1955 - accuracy: 0.9669 - val_loss: 0.1251 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 89/300\n",
            "38/38 - 2s - loss: 0.1987 - accuracy: 0.9652 - val_loss: 0.1297 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 90/300\n",
            "38/38 - 2s - loss: 0.1756 - accuracy: 0.9702 - val_loss: 0.1237 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 91/300\n",
            "38/38 - 2s - loss: 0.1686 - accuracy: 0.9834 - val_loss: 0.1337 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 92/300\n",
            "38/38 - 2s - loss: 0.1694 - accuracy: 0.9851 - val_loss: 0.1291 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 93/300\n",
            "38/38 - 2s - loss: 0.1742 - accuracy: 0.9735 - val_loss: 0.1346 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 94/300\n",
            "38/38 - 2s - loss: 0.1695 - accuracy: 0.9752 - val_loss: 0.1211 - val_accuracy: 0.9934 - 2s/epoch - 61ms/step\n",
            "Epoch 95/300\n",
            "38/38 - 2s - loss: 0.1594 - accuracy: 0.9801 - val_loss: 0.1317 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 96/300\n",
            "38/38 - 2s - loss: 0.1789 - accuracy: 0.9719 - val_loss: 0.1234 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 97/300\n",
            "38/38 - 2s - loss: 0.1691 - accuracy: 0.9752 - val_loss: 0.1207 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 98/300\n",
            "38/38 - 2s - loss: 0.1862 - accuracy: 0.9702 - val_loss: 0.1214 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 99/300\n",
            "38/38 - 2s - loss: 0.1837 - accuracy: 0.9768 - val_loss: 0.1198 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 100/300\n",
            "38/38 - 2s - loss: 0.1565 - accuracy: 0.9851 - val_loss: 0.1282 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 101/300\n",
            "38/38 - 2s - loss: 0.1593 - accuracy: 0.9834 - val_loss: 0.1149 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 102/300\n",
            "38/38 - 2s - loss: 0.1570 - accuracy: 0.9785 - val_loss: 0.1110 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 103/300\n",
            "38/38 - 3s - loss: 0.1551 - accuracy: 0.9785 - val_loss: 0.1119 - val_accuracy: 0.9934 - 3s/epoch - 90ms/step\n",
            "Epoch 104/300\n",
            "38/38 - 3s - loss: 0.1685 - accuracy: 0.9685 - val_loss: 0.1264 - val_accuracy: 0.9868 - 3s/epoch - 77ms/step\n",
            "Epoch 105/300\n",
            "38/38 - 2s - loss: 0.1620 - accuracy: 0.9768 - val_loss: 0.1145 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 106/300\n",
            "38/38 - 2s - loss: 0.1422 - accuracy: 0.9801 - val_loss: 0.1226 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 107/300\n",
            "38/38 - 2s - loss: 0.1763 - accuracy: 0.9685 - val_loss: 0.1140 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 108/300\n",
            "38/38 - 2s - loss: 0.1534 - accuracy: 0.9801 - val_loss: 0.1150 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 109/300\n",
            "38/38 - 2s - loss: 0.1532 - accuracy: 0.9768 - val_loss: 0.1219 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 110/300\n",
            "38/38 - 2s - loss: 0.1566 - accuracy: 0.9752 - val_loss: 0.1093 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 111/300\n",
            "38/38 - 2s - loss: 0.1388 - accuracy: 0.9818 - val_loss: 0.1003 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 112/300\n",
            "38/38 - 2s - loss: 0.1425 - accuracy: 0.9785 - val_loss: 0.0941 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 113/300\n",
            "38/38 - 2s - loss: 0.1583 - accuracy: 0.9735 - val_loss: 0.0999 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 114/300\n",
            "38/38 - 2s - loss: 0.1446 - accuracy: 0.9834 - val_loss: 0.0958 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 115/300\n",
            "38/38 - 2s - loss: 0.1541 - accuracy: 0.9719 - val_loss: 0.1010 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 116/300\n",
            "38/38 - 2s - loss: 0.1581 - accuracy: 0.9768 - val_loss: 0.1039 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 117/300\n",
            "38/38 - 2s - loss: 0.1414 - accuracy: 0.9868 - val_loss: 0.0899 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 118/300\n",
            "38/38 - 2s - loss: 0.1269 - accuracy: 0.9785 - val_loss: 0.0960 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 119/300\n",
            "38/38 - 2s - loss: 0.1363 - accuracy: 0.9851 - val_loss: 0.1001 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 120/300\n",
            "38/38 - 2s - loss: 0.1364 - accuracy: 0.9752 - val_loss: 0.0914 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 121/300\n",
            "38/38 - 2s - loss: 0.1421 - accuracy: 0.9752 - val_loss: 0.0881 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 122/300\n",
            "38/38 - 2s - loss: 0.1436 - accuracy: 0.9785 - val_loss: 0.0877 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 123/300\n",
            "38/38 - 2s - loss: 0.1251 - accuracy: 0.9884 - val_loss: 0.0927 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 124/300\n",
            "38/38 - 2s - loss: 0.1205 - accuracy: 0.9851 - val_loss: 0.0889 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 125/300\n",
            "38/38 - 2s - loss: 0.1284 - accuracy: 0.9818 - val_loss: 0.0887 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 126/300\n",
            "38/38 - 2s - loss: 0.1450 - accuracy: 0.9768 - val_loss: 0.0971 - val_accuracy: 0.9803 - 2s/epoch - 58ms/step\n",
            "Epoch 127/300\n",
            "38/38 - 2s - loss: 0.1421 - accuracy: 0.9752 - val_loss: 0.0972 - val_accuracy: 0.9803 - 2s/epoch - 59ms/step\n",
            "Epoch 128/300\n",
            "38/38 - 2s - loss: 0.1352 - accuracy: 0.9801 - val_loss: 0.0846 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 129/300\n",
            "38/38 - 2s - loss: 0.1435 - accuracy: 0.9719 - val_loss: 0.0859 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 130/300\n",
            "38/38 - 2s - loss: 0.1332 - accuracy: 0.9818 - val_loss: 0.0856 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 131/300\n",
            "38/38 - 2s - loss: 0.1227 - accuracy: 0.9834 - val_loss: 0.0798 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 132/300\n",
            "38/38 - 2s - loss: 0.1181 - accuracy: 0.9868 - val_loss: 0.0789 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 133/300\n",
            "38/38 - 2s - loss: 0.1261 - accuracy: 0.9735 - val_loss: 0.0780 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 134/300\n",
            "38/38 - 2s - loss: 0.1158 - accuracy: 0.9801 - val_loss: 0.0802 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 135/300\n",
            "38/38 - 2s - loss: 0.1374 - accuracy: 0.9685 - val_loss: 0.0791 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 136/300\n",
            "38/38 - 2s - loss: 0.1413 - accuracy: 0.9768 - val_loss: 0.0775 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 137/300\n",
            "38/38 - 2s - loss: 0.1171 - accuracy: 0.9851 - val_loss: 0.0824 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 138/300\n",
            "38/38 - 2s - loss: 0.1194 - accuracy: 0.9735 - val_loss: 0.0819 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 139/300\n",
            "38/38 - 2s - loss: 0.1261 - accuracy: 0.9818 - val_loss: 0.0947 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 140/300\n",
            "38/38 - 2s - loss: 0.1275 - accuracy: 0.9768 - val_loss: 0.0848 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 141/300\n",
            "38/38 - 2s - loss: 0.1206 - accuracy: 0.9768 - val_loss: 0.0865 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 142/300\n",
            "38/38 - 2s - loss: 0.1166 - accuracy: 0.9851 - val_loss: 0.0813 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 143/300\n",
            "38/38 - 2s - loss: 0.1039 - accuracy: 0.9868 - val_loss: 0.0853 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 144/300\n",
            "38/38 - 2s - loss: 0.1142 - accuracy: 0.9768 - val_loss: 0.0836 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 145/300\n",
            "38/38 - 2s - loss: 0.1164 - accuracy: 0.9868 - val_loss: 0.0747 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 146/300\n",
            "38/38 - 2s - loss: 0.1179 - accuracy: 0.9818 - val_loss: 0.0693 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 147/300\n",
            "38/38 - 2s - loss: 0.1145 - accuracy: 0.9818 - val_loss: 0.0818 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 148/300\n",
            "38/38 - 2s - loss: 0.1067 - accuracy: 0.9834 - val_loss: 0.0708 - val_accuracy: 0.9934 - 2s/epoch - 63ms/step\n",
            "Epoch 149/300\n",
            "38/38 - 4s - loss: 0.1054 - accuracy: 0.9917 - val_loss: 0.0716 - val_accuracy: 0.9934 - 4s/epoch - 100ms/step\n",
            "Epoch 150/300\n",
            "38/38 - 2s - loss: 0.1081 - accuracy: 0.9801 - val_loss: 0.0702 - val_accuracy: 0.9934 - 2s/epoch - 62ms/step\n",
            "Epoch 151/300\n",
            "38/38 - 2s - loss: 0.1307 - accuracy: 0.9801 - val_loss: 0.0717 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 152/300\n",
            "38/38 - 2s - loss: 0.1262 - accuracy: 0.9768 - val_loss: 0.0690 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 153/300\n",
            "38/38 - 2s - loss: 0.1087 - accuracy: 0.9868 - val_loss: 0.0627 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 154/300\n",
            "38/38 - 2s - loss: 0.1143 - accuracy: 0.9818 - val_loss: 0.0663 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 155/300\n",
            "38/38 - 2s - loss: 0.1070 - accuracy: 0.9884 - val_loss: 0.0710 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 156/300\n",
            "38/38 - 2s - loss: 0.1168 - accuracy: 0.9785 - val_loss: 0.0712 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 157/300\n",
            "38/38 - 2s - loss: 0.0968 - accuracy: 0.9801 - val_loss: 0.0769 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 158/300\n",
            "38/38 - 2s - loss: 0.1061 - accuracy: 0.9801 - val_loss: 0.0647 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 159/300\n",
            "38/38 - 2s - loss: 0.1184 - accuracy: 0.9785 - val_loss: 0.0733 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 160/300\n",
            "38/38 - 2s - loss: 0.1116 - accuracy: 0.9818 - val_loss: 0.0730 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 161/300\n",
            "38/38 - 2s - loss: 0.1043 - accuracy: 0.9768 - val_loss: 0.0634 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 162/300\n",
            "38/38 - 2s - loss: 0.0863 - accuracy: 0.9917 - val_loss: 0.0726 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 163/300\n",
            "38/38 - 2s - loss: 0.1057 - accuracy: 0.9801 - val_loss: 0.0686 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 164/300\n",
            "38/38 - 2s - loss: 0.0929 - accuracy: 0.9884 - val_loss: 0.0717 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 165/300\n",
            "38/38 - 2s - loss: 0.1076 - accuracy: 0.9818 - val_loss: 0.0692 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 166/300\n",
            "38/38 - 2s - loss: 0.0970 - accuracy: 0.9868 - val_loss: 0.0763 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 167/300\n",
            "38/38 - 2s - loss: 0.1047 - accuracy: 0.9834 - val_loss: 0.0614 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 168/300\n",
            "38/38 - 2s - loss: 0.1061 - accuracy: 0.9785 - val_loss: 0.0622 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 169/300\n",
            "38/38 - 2s - loss: 0.0939 - accuracy: 0.9868 - val_loss: 0.0688 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 170/300\n",
            "38/38 - 2s - loss: 0.1038 - accuracy: 0.9801 - val_loss: 0.0634 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 171/300\n",
            "38/38 - 2s - loss: 0.0847 - accuracy: 0.9851 - val_loss: 0.0628 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 172/300\n",
            "38/38 - 2s - loss: 0.1144 - accuracy: 0.9785 - val_loss: 0.0604 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 173/300\n",
            "38/38 - 2s - loss: 0.0904 - accuracy: 0.9901 - val_loss: 0.0616 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 174/300\n",
            "38/38 - 2s - loss: 0.0845 - accuracy: 0.9868 - val_loss: 0.0612 - val_accuracy: 0.9868 - 2s/epoch - 58ms/step\n",
            "Epoch 175/300\n",
            "38/38 - 2s - loss: 0.0944 - accuracy: 0.9851 - val_loss: 0.0623 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 176/300\n",
            "38/38 - 2s - loss: 0.1165 - accuracy: 0.9785 - val_loss: 0.0621 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 177/300\n",
            "38/38 - 2s - loss: 0.1030 - accuracy: 0.9768 - val_loss: 0.0545 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 178/300\n",
            "38/38 - 2s - loss: 0.0970 - accuracy: 0.9901 - val_loss: 0.0585 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 179/300\n",
            "38/38 - 2s - loss: 0.1031 - accuracy: 0.9752 - val_loss: 0.0560 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 180/300\n",
            "38/38 - 2s - loss: 0.1152 - accuracy: 0.9719 - val_loss: 0.0698 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 181/300\n",
            "38/38 - 2s - loss: 0.1050 - accuracy: 0.9768 - val_loss: 0.0564 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 182/300\n",
            "38/38 - 2s - loss: 0.0883 - accuracy: 0.9884 - val_loss: 0.0565 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 183/300\n",
            "38/38 - 2s - loss: 0.0868 - accuracy: 0.9868 - val_loss: 0.0566 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 184/300\n",
            "38/38 - 2s - loss: 0.0811 - accuracy: 0.9934 - val_loss: 0.0626 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 185/300\n",
            "38/38 - 2s - loss: 0.0843 - accuracy: 0.9868 - val_loss: 0.0540 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 186/300\n",
            "38/38 - 2s - loss: 0.0992 - accuracy: 0.9834 - val_loss: 0.0519 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 187/300\n",
            "38/38 - 2s - loss: 0.0803 - accuracy: 0.9917 - val_loss: 0.0474 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 188/300\n",
            "38/38 - 2s - loss: 0.0867 - accuracy: 0.9834 - val_loss: 0.0527 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 189/300\n",
            "38/38 - 2s - loss: 0.0835 - accuracy: 0.9818 - val_loss: 0.0560 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 190/300\n",
            "38/38 - 2s - loss: 0.0968 - accuracy: 0.9801 - val_loss: 0.0617 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 191/300\n",
            "38/38 - 2s - loss: 0.1031 - accuracy: 0.9785 - val_loss: 0.0539 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 192/300\n",
            "38/38 - 2s - loss: 0.0888 - accuracy: 0.9884 - val_loss: 0.0524 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 193/300\n",
            "38/38 - 2s - loss: 0.0749 - accuracy: 0.9884 - val_loss: 0.0590 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 194/300\n",
            "38/38 - 3s - loss: 0.0808 - accuracy: 0.9884 - val_loss: 0.0584 - val_accuracy: 0.9934 - 3s/epoch - 79ms/step\n",
            "Epoch 195/300\n",
            "38/38 - 3s - loss: 0.0695 - accuracy: 0.9917 - val_loss: 0.0516 - val_accuracy: 0.9934 - 3s/epoch - 87ms/step\n",
            "Epoch 196/300\n",
            "38/38 - 2s - loss: 0.0771 - accuracy: 0.9818 - val_loss: 0.0536 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 197/300\n",
            "38/38 - 2s - loss: 0.1010 - accuracy: 0.9768 - val_loss: 0.0578 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 198/300\n",
            "38/38 - 2s - loss: 0.0799 - accuracy: 0.9834 - val_loss: 0.0534 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 199/300\n",
            "38/38 - 2s - loss: 0.0812 - accuracy: 0.9851 - val_loss: 0.0454 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 200/300\n",
            "38/38 - 2s - loss: 0.0910 - accuracy: 0.9851 - val_loss: 0.0474 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 201/300\n",
            "38/38 - 2s - loss: 0.0881 - accuracy: 0.9884 - val_loss: 0.0615 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 202/300\n",
            "38/38 - 2s - loss: 0.0789 - accuracy: 0.9917 - val_loss: 0.0513 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 203/300\n",
            "38/38 - 2s - loss: 0.0854 - accuracy: 0.9884 - val_loss: 0.0511 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 204/300\n",
            "38/38 - 2s - loss: 0.0944 - accuracy: 0.9785 - val_loss: 0.0545 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 205/300\n",
            "38/38 - 2s - loss: 0.0816 - accuracy: 0.9818 - val_loss: 0.0600 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 206/300\n",
            "38/38 - 2s - loss: 0.0850 - accuracy: 0.9851 - val_loss: 0.0533 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 207/300\n",
            "38/38 - 2s - loss: 0.0816 - accuracy: 0.9950 - val_loss: 0.0623 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 208/300\n",
            "38/38 - 2s - loss: 0.0868 - accuracy: 0.9801 - val_loss: 0.0561 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 209/300\n",
            "38/38 - 2s - loss: 0.0788 - accuracy: 0.9884 - val_loss: 0.0578 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 210/300\n",
            "38/38 - 2s - loss: 0.0843 - accuracy: 0.9884 - val_loss: 0.0496 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 211/300\n",
            "38/38 - 2s - loss: 0.0776 - accuracy: 0.9868 - val_loss: 0.0617 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 212/300\n",
            "38/38 - 2s - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.0666 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 213/300\n",
            "38/38 - 2s - loss: 0.0882 - accuracy: 0.9801 - val_loss: 0.0457 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 214/300\n",
            "38/38 - 2s - loss: 0.0809 - accuracy: 0.9801 - val_loss: 0.0589 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 215/300\n",
            "38/38 - 2s - loss: 0.0782 - accuracy: 0.9868 - val_loss: 0.0517 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 216/300\n",
            "38/38 - 2s - loss: 0.0902 - accuracy: 0.9785 - val_loss: 0.0509 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 217/300\n",
            "38/38 - 2s - loss: 0.0794 - accuracy: 0.9851 - val_loss: 0.0586 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 218/300\n",
            "38/38 - 2s - loss: 0.0783 - accuracy: 0.9851 - val_loss: 0.0425 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 219/300\n",
            "38/38 - 2s - loss: 0.0771 - accuracy: 0.9917 - val_loss: 0.0414 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 220/300\n",
            "38/38 - 2s - loss: 0.0828 - accuracy: 0.9851 - val_loss: 0.0506 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 221/300\n",
            "38/38 - 2s - loss: 0.0752 - accuracy: 0.9868 - val_loss: 0.0557 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 222/300\n",
            "38/38 - 2s - loss: 0.0861 - accuracy: 0.9834 - val_loss: 0.0551 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 223/300\n",
            "38/38 - 2s - loss: 0.0755 - accuracy: 0.9801 - val_loss: 0.0510 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 224/300\n",
            "38/38 - 2s - loss: 0.0787 - accuracy: 0.9868 - val_loss: 0.0665 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 225/300\n",
            "38/38 - 2s - loss: 0.0731 - accuracy: 0.9901 - val_loss: 0.0524 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 226/300\n",
            "38/38 - 2s - loss: 0.0795 - accuracy: 0.9851 - val_loss: 0.0556 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 227/300\n",
            "38/38 - 2s - loss: 0.0708 - accuracy: 0.9901 - val_loss: 0.0588 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 228/300\n",
            "38/38 - 2s - loss: 0.0710 - accuracy: 0.9868 - val_loss: 0.0490 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 229/300\n",
            "38/38 - 2s - loss: 0.0661 - accuracy: 0.9884 - val_loss: 0.0498 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 230/300\n",
            "38/38 - 2s - loss: 0.0791 - accuracy: 0.9801 - val_loss: 0.0582 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 231/300\n",
            "38/38 - 2s - loss: 0.0818 - accuracy: 0.9934 - val_loss: 0.0509 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 232/300\n",
            "38/38 - 2s - loss: 0.0672 - accuracy: 0.9834 - val_loss: 0.0532 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 233/300\n",
            "38/38 - 2s - loss: 0.0569 - accuracy: 0.9950 - val_loss: 0.0529 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 234/300\n",
            "38/38 - 2s - loss: 0.0785 - accuracy: 0.9851 - val_loss: 0.0483 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 235/300\n",
            "38/38 - 2s - loss: 0.0836 - accuracy: 0.9818 - val_loss: 0.0505 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 236/300\n",
            "38/38 - 2s - loss: 0.0635 - accuracy: 0.9901 - val_loss: 0.0462 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 237/300\n",
            "38/38 - 2s - loss: 0.0638 - accuracy: 0.9917 - val_loss: 0.0428 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 238/300\n",
            "38/38 - 2s - loss: 0.0789 - accuracy: 0.9801 - val_loss: 0.0429 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 239/300\n",
            "38/38 - 2s - loss: 0.0614 - accuracy: 0.9917 - val_loss: 0.0487 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 240/300\n",
            "38/38 - 3s - loss: 0.0696 - accuracy: 0.9834 - val_loss: 0.0517 - val_accuracy: 0.9934 - 3s/epoch - 81ms/step\n",
            "Epoch 241/300\n",
            "38/38 - 3s - loss: 0.0793 - accuracy: 0.9818 - val_loss: 0.0393 - val_accuracy: 0.9934 - 3s/epoch - 84ms/step\n",
            "Epoch 242/300\n",
            "38/38 - 2s - loss: 0.0836 - accuracy: 0.9851 - val_loss: 0.0565 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 243/300\n",
            "38/38 - 2s - loss: 0.0795 - accuracy: 0.9818 - val_loss: 0.0612 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 244/300\n",
            "38/38 - 2s - loss: 0.0700 - accuracy: 0.9901 - val_loss: 0.0509 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 245/300\n",
            "38/38 - 2s - loss: 0.0852 - accuracy: 0.9818 - val_loss: 0.0515 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 246/300\n",
            "38/38 - 2s - loss: 0.0685 - accuracy: 0.9834 - val_loss: 0.0468 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 247/300\n",
            "38/38 - 2s - loss: 0.0644 - accuracy: 0.9901 - val_loss: 0.0474 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 248/300\n",
            "38/38 - 2s - loss: 0.0640 - accuracy: 0.9917 - val_loss: 0.0455 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 249/300\n",
            "38/38 - 2s - loss: 0.0804 - accuracy: 0.9818 - val_loss: 0.0415 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 250/300\n",
            "38/38 - 2s - loss: 0.0705 - accuracy: 0.9818 - val_loss: 0.0440 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 251/300\n",
            "38/38 - 2s - loss: 0.0657 - accuracy: 0.9851 - val_loss: 0.0420 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 252/300\n",
            "38/38 - 2s - loss: 0.0671 - accuracy: 0.9868 - val_loss: 0.0540 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 253/300\n",
            "38/38 - 2s - loss: 0.0717 - accuracy: 0.9901 - val_loss: 0.0431 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 254/300\n",
            "38/38 - 2s - loss: 0.0857 - accuracy: 0.9818 - val_loss: 0.0475 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 255/300\n",
            "38/38 - 2s - loss: 0.0586 - accuracy: 0.9934 - val_loss: 0.0485 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 256/300\n",
            "38/38 - 2s - loss: 0.0677 - accuracy: 0.9884 - val_loss: 0.0343 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 257/300\n",
            "38/38 - 2s - loss: 0.0914 - accuracy: 0.9768 - val_loss: 0.0497 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 258/300\n",
            "38/38 - 2s - loss: 0.0613 - accuracy: 0.9934 - val_loss: 0.0382 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 259/300\n",
            "38/38 - 2s - loss: 0.0607 - accuracy: 0.9950 - val_loss: 0.0449 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 260/300\n",
            "38/38 - 2s - loss: 0.0601 - accuracy: 0.9868 - val_loss: 0.0448 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 261/300\n",
            "38/38 - 2s - loss: 0.0642 - accuracy: 0.9884 - val_loss: 0.0365 - val_accuracy: 0.9868 - 2s/epoch - 59ms/step\n",
            "Epoch 262/300\n",
            "38/38 - 2s - loss: 0.0756 - accuracy: 0.9818 - val_loss: 0.0300 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 263/300\n",
            "38/38 - 2s - loss: 0.0640 - accuracy: 0.9917 - val_loss: 0.0369 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 264/300\n",
            "38/38 - 2s - loss: 0.0824 - accuracy: 0.9818 - val_loss: 0.0493 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 265/300\n",
            "38/38 - 2s - loss: 0.0605 - accuracy: 0.9884 - val_loss: 0.0395 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 266/300\n",
            "38/38 - 2s - loss: 0.0586 - accuracy: 0.9917 - val_loss: 0.0437 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 267/300\n",
            "38/38 - 2s - loss: 0.0503 - accuracy: 0.9934 - val_loss: 0.0431 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 268/300\n",
            "38/38 - 2s - loss: 0.0678 - accuracy: 0.9884 - val_loss: 0.0438 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 269/300\n",
            "38/38 - 2s - loss: 0.0718 - accuracy: 0.9884 - val_loss: 0.0368 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 270/300\n",
            "38/38 - 2s - loss: 0.0581 - accuracy: 0.9851 - val_loss: 0.0359 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 271/300\n",
            "38/38 - 2s - loss: 0.0603 - accuracy: 0.9934 - val_loss: 0.0435 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 272/300\n",
            "38/38 - 2s - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.0358 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 273/300\n",
            "38/38 - 2s - loss: 0.0569 - accuracy: 0.9884 - val_loss: 0.0304 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 274/300\n",
            "38/38 - 2s - loss: 0.0624 - accuracy: 0.9868 - val_loss: 0.0340 - val_accuracy: 1.0000 - 2s/epoch - 59ms/step\n",
            "Epoch 275/300\n",
            "38/38 - 2s - loss: 0.0676 - accuracy: 0.9884 - val_loss: 0.0360 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 276/300\n",
            "38/38 - 2s - loss: 0.0501 - accuracy: 0.9950 - val_loss: 0.0394 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 277/300\n",
            "38/38 - 2s - loss: 0.0604 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 278/300\n",
            "38/38 - 2s - loss: 0.0654 - accuracy: 0.9868 - val_loss: 0.0345 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 279/300\n",
            "38/38 - 2s - loss: 0.0574 - accuracy: 0.9917 - val_loss: 0.0361 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 280/300\n",
            "38/38 - 2s - loss: 0.0635 - accuracy: 0.9851 - val_loss: 0.0352 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 281/300\n",
            "38/38 - 2s - loss: 0.0666 - accuracy: 0.9834 - val_loss: 0.0462 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 282/300\n",
            "38/38 - 2s - loss: 0.0550 - accuracy: 0.9934 - val_loss: 0.0426 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 283/300\n",
            "38/38 - 2s - loss: 0.0525 - accuracy: 0.9917 - val_loss: 0.0460 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 284/300\n",
            "38/38 - 2s - loss: 0.0579 - accuracy: 0.9868 - val_loss: 0.0330 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 285/300\n",
            "38/38 - 2s - loss: 0.0630 - accuracy: 0.9834 - val_loss: 0.0448 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 286/300\n",
            "38/38 - 3s - loss: 0.0606 - accuracy: 0.9884 - val_loss: 0.0354 - val_accuracy: 0.9934 - 3s/epoch - 73ms/step\n",
            "Epoch 287/300\n",
            "38/38 - 4s - loss: 0.0538 - accuracy: 0.9901 - val_loss: 0.0564 - val_accuracy: 0.9934 - 4s/epoch - 93ms/step\n",
            "Epoch 288/300\n",
            "38/38 - 2s - loss: 0.0616 - accuracy: 0.9834 - val_loss: 0.0397 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 289/300\n",
            "38/38 - 2s - loss: 0.0830 - accuracy: 0.9752 - val_loss: 0.0463 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 290/300\n",
            "38/38 - 2s - loss: 0.0547 - accuracy: 0.9950 - val_loss: 0.0320 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 291/300\n",
            "38/38 - 2s - loss: 0.0507 - accuracy: 0.9917 - val_loss: 0.0473 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 292/300\n",
            "38/38 - 2s - loss: 0.0523 - accuracy: 0.9917 - val_loss: 0.0537 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 293/300\n",
            "38/38 - 2s - loss: 0.0468 - accuracy: 0.9950 - val_loss: 0.0361 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 294/300\n",
            "38/38 - 2s - loss: 0.0584 - accuracy: 0.9851 - val_loss: 0.0450 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 295/300\n",
            "38/38 - 2s - loss: 0.0539 - accuracy: 0.9901 - val_loss: 0.0561 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 296/300\n",
            "38/38 - 2s - loss: 0.0609 - accuracy: 0.9851 - val_loss: 0.0424 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 297/300\n",
            "38/38 - 2s - loss: 0.0651 - accuracy: 0.9834 - val_loss: 0.0312 - val_accuracy: 0.9934 - 2s/epoch - 60ms/step\n",
            "Epoch 298/300\n",
            "38/38 - 2s - loss: 0.0647 - accuracy: 0.9917 - val_loss: 0.0423 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n",
            "Epoch 299/300\n",
            "38/38 - 2s - loss: 0.0483 - accuracy: 0.9950 - val_loss: 0.0361 - val_accuracy: 0.9934 - 2s/epoch - 59ms/step\n",
            "Epoch 300/300\n",
            "38/38 - 2s - loss: 0.0567 - accuracy: 0.9884 - val_loss: 0.0436 - val_accuracy: 0.9934 - 2s/epoch - 58ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nans_test=model.predict(nX_test)\n",
        "print(nans_test.shape)\n",
        "nans=[]\n",
        "for i in nans_test:\n",
        "  # print(i)\n",
        "  nans.append(np.argmax(i))\n",
        "\n",
        "nans=np.array(nans).reshape(190,1).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJM0NGLGouSA",
        "outputId": "4bc1c21b-0ccf-422a-f8c2-cd2c39eeb309"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 23ms/step\n",
            "(190, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(fittedModel.history['accuracy'])\n",
        "# plt.plot(fittedModel.history['val_accuracy'])\n",
        "plt.plot(fittedModel.history['loss'])\n",
        "plt.plot(fittedModel.history['val_loss'])\n",
        "plt.title('EGGNet loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss','val_loss'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "PlaMbvy-2lpW",
        "outputId": "7018e09b-27e9-4a73-9298-a0a992bc2ab6"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = \"...\"\n",
        "assert(nans.shape == (190, 1))\n",
        "np.savetxt('eegnet_output.csv', nans,fmt='%i', delimiter=\",\")\n",
        "np.savetxt('competition_output.csv', nans,fmt='%i', delimiter=\",\")"
      ],
      "metadata": {
        "id": "Ge8jZUU8gve3"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Competition Part"
      ],
      "metadata": {
        "id": "qnHnQ_yVerBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model here:\n"
      ],
      "metadata": {
        "id": "zlhO90b9iB_-"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = \"...\"\n",
        "assert(output.shape == (190, 1))\n",
        "np.savetxt('competition_output.csv', output, delimiter=\",\")"
      ],
      "metadata": {
        "id": "m097nvkXiIqY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fb422447-c922-4012-99d4-f0fdc386b4c1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-26137f07401b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m190\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'competition_output.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}