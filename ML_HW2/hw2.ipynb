{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h2ibEyDa46X2",
        "zrQXqH475G8-",
        "BhtqUTG9Nlyz",
        "61hPUYvy6MTB",
        "rP0SU7tTweOX",
        "GfKSt2gH74Uu",
        "tFgbUY_ajVOK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive (optional)"
      ],
      "metadata": {
        "id": "fI00-KuddN2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "# os.chdir(\"/content/drive/MyDrive/....\")  # file path\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "Uf6ucZcj6kpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2a1bcd-69a9-497e-b2e5-0cfa1e0bdf6f"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW2 : Decision Tree and Random Forest**\n",
        "In *assignment 2*, you need to finish :\n",
        "\n",
        "1. Basic Part : Implement a **Decision Tree** model and predict whether the patients in the validation set have diabetes\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Calculate the Entropy and Information Gain\n",
        "> * Step 3 : Find the Best Split\n",
        "> * Step 4 : Split into 2 branches\n",
        "> * Step 5 : Build decision tree\n",
        "> * Step 6 : Save the answers from step2 to step5\n",
        "> * Step 7 : Split data into training set and validation set\n",
        "> * Step 8 : Train a decision tree model with training set\n",
        "> * Step 9 : Predict the cases in the *validation set* by using the model trained in *Step8*\n",
        "> * Step 10 : Calculate the f1-score of your predictions in *Step9*\n",
        "> * Step 11 : Write the Output File\n",
        "\n",
        "2. Advanced Part : Build a **Random Forest** model to make predictions\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Load the test data\n",
        "> * Step 3 : Build a random forest\n",
        "> * Step 4 : Predict the cases in the test data by using the model trained in *Step3*\n",
        "> * Step 5 : Save the predictions(from *Step 4*) in a csv file\n",
        "\n"
      ],
      "metadata": {
        "id": "yvRo67Io4NKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Part** (60%)\n",
        "In this part, your need to implement a Decision Tree model by completing the following given functions.\n",
        "\n",
        "Also, you need to run these functions with the given input variables and save the output in a csv file **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "wwVh8lYD4kbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages\n",
        "\n",
        "\n",
        "> Note : You **cannot** import any other packages in both basic part and advanced part\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h2ibEyDa46X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from numpy import sqrt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "RMjaYVZD6kmb"
      },
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_basic.csv**"
      ],
      "metadata": {
        "id": "zrQXqH475G8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pd.read_csv('hw2_input_basic.csv')\n",
        "input_data"
      ],
      "metadata": {
        "id": "0n3gcL2l6kjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "db253f93-c397-40c9-d45e-e6bc8bbf4afb"
      },
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age        bmi  gender  height  weight  glucose_apache  \\\n",
              "0   70.0  25.984659       1   172.7   77.50           116.0   \n",
              "1   30.0  31.310368       1   170.2   90.70            71.0   \n",
              "2   54.0  24.388824       1   177.8   77.10           120.0   \n",
              "3   65.0  34.141074       0   170.2   98.90            73.0   \n",
              "4   49.0  22.564743       1   172.7   67.30           207.0   \n",
              "5   62.0  29.424010       0   154.9   70.60           113.0   \n",
              "6   85.0  27.673574       1   154.9   66.40           102.0   \n",
              "7   65.0  22.269432       1   177.8   70.40           333.0   \n",
              "8   85.0  35.879362       0   165.1   97.80           124.0   \n",
              "9   81.0  20.859375       0   160.0   53.40           136.0   \n",
              "10  59.0  46.409136       0   162.6  122.70           169.0   \n",
              "11  77.0  32.324734       0   154.9   77.56           264.0   \n",
              "12  68.0  15.913579       1   185.4   54.70            39.0   \n",
              "13  51.0  24.028492       1   190.5   87.20            80.0   \n",
              "14  76.0  34.216873       0   154.9   82.10           306.0   \n",
              "15  48.0  26.516476       1   180.3   86.20            96.0   \n",
              "16  82.0  18.921389       0   154.9   45.40           164.0   \n",
              "17  78.0  36.668167       0   167.6  103.00           282.0   \n",
              "18  62.0  19.108088       1   157.5   47.40           275.0   \n",
              "19  73.0  22.851562       0   160.0   58.50           178.0   \n",
              "20  73.0  20.351971       0   167.5   57.10           159.0   \n",
              "21  59.0  27.109238       1   177.8   85.70            85.0   \n",
              "22  51.0  37.954367       0   172.7  113.20           168.0   \n",
              "23  80.0  36.267895       1   180.3  117.90           138.0   \n",
              "24  74.0  25.856081       1   170.2   74.90           145.0   \n",
              "25  61.0  29.161972       1   180.3   94.80           267.0   \n",
              "26  74.0  38.111136       1   188.0  134.70           279.0   \n",
              "27  65.0  53.414791       0   166.4  147.90           121.0   \n",
              "28  38.0  33.438787       0   161.3   87.00           135.0   \n",
              "29  82.0  32.263238       0   162.6   85.30           111.0   \n",
              "\n",
              "    heart_rate_apache  resprate_apache  sodium_apache  diabetes_mellitus  \n",
              "0               101.0             49.0          137.0                  0  \n",
              "1                39.0             33.0          144.0                  0  \n",
              "2               120.0             31.0          141.0                  0  \n",
              "3                48.0             36.0          140.0                  1  \n",
              "4               119.0              6.0          144.0                  0  \n",
              "5                60.0             32.0          137.0                  0  \n",
              "6                49.0             36.0          142.0                  0  \n",
              "7                59.0              6.0          145.0                  1  \n",
              "8                92.0             30.0          136.0                  0  \n",
              "9               118.0             52.0          138.0                  0  \n",
              "10              100.0             46.0          138.0                  0  \n",
              "11               90.0             37.0          141.0                  1  \n",
              "12              108.0             45.0          135.0                  0  \n",
              "13               61.0             30.0          139.0                  0  \n",
              "14              112.0             40.0          130.0                  1  \n",
              "15              133.0             31.0          137.0                  0  \n",
              "16              103.0             48.0          134.0                  0  \n",
              "17              104.0             42.0          138.0                  1  \n",
              "18              108.0             38.0          131.0                  1  \n",
              "19              154.0             55.0          138.0                  1  \n",
              "20              110.0             27.0          139.0                  0  \n",
              "21               92.0              6.0          143.0                  0  \n",
              "22               60.0             43.0          119.0                  1  \n",
              "23              178.0             43.0          140.0                  1  \n",
              "24               40.0             16.0          146.0                  1  \n",
              "25               62.0             58.0          134.0                  1  \n",
              "26              112.0             43.0          132.0                  1  \n",
              "27               88.0             32.0          142.0                  0  \n",
              "28               46.0             28.0          138.0                  0  \n",
              "29              114.0             22.0          143.0                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8843f732-c893-4db2-bad8-1cdfb52ccdab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>glucose_apache</th>\n",
              "      <th>heart_rate_apache</th>\n",
              "      <th>resprate_apache</th>\n",
              "      <th>sodium_apache</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70.0</td>\n",
              "      <td>25.984659</td>\n",
              "      <td>1</td>\n",
              "      <td>172.7</td>\n",
              "      <td>77.50</td>\n",
              "      <td>116.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.0</td>\n",
              "      <td>31.310368</td>\n",
              "      <td>1</td>\n",
              "      <td>170.2</td>\n",
              "      <td>90.70</td>\n",
              "      <td>71.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54.0</td>\n",
              "      <td>24.388824</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>77.10</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65.0</td>\n",
              "      <td>34.141074</td>\n",
              "      <td>0</td>\n",
              "      <td>170.2</td>\n",
              "      <td>98.90</td>\n",
              "      <td>73.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.0</td>\n",
              "      <td>22.564743</td>\n",
              "      <td>1</td>\n",
              "      <td>172.7</td>\n",
              "      <td>67.30</td>\n",
              "      <td>207.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>62.0</td>\n",
              "      <td>29.424010</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>70.60</td>\n",
              "      <td>113.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>85.0</td>\n",
              "      <td>27.673574</td>\n",
              "      <td>1</td>\n",
              "      <td>154.9</td>\n",
              "      <td>66.40</td>\n",
              "      <td>102.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>65.0</td>\n",
              "      <td>22.269432</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>70.40</td>\n",
              "      <td>333.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85.0</td>\n",
              "      <td>35.879362</td>\n",
              "      <td>0</td>\n",
              "      <td>165.1</td>\n",
              "      <td>97.80</td>\n",
              "      <td>124.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>81.0</td>\n",
              "      <td>20.859375</td>\n",
              "      <td>0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>53.40</td>\n",
              "      <td>136.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>59.0</td>\n",
              "      <td>46.409136</td>\n",
              "      <td>0</td>\n",
              "      <td>162.6</td>\n",
              "      <td>122.70</td>\n",
              "      <td>169.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>77.0</td>\n",
              "      <td>32.324734</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>77.56</td>\n",
              "      <td>264.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>68.0</td>\n",
              "      <td>15.913579</td>\n",
              "      <td>1</td>\n",
              "      <td>185.4</td>\n",
              "      <td>54.70</td>\n",
              "      <td>39.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>51.0</td>\n",
              "      <td>24.028492</td>\n",
              "      <td>1</td>\n",
              "      <td>190.5</td>\n",
              "      <td>87.20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>76.0</td>\n",
              "      <td>34.216873</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>82.10</td>\n",
              "      <td>306.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>48.0</td>\n",
              "      <td>26.516476</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>86.20</td>\n",
              "      <td>96.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>82.0</td>\n",
              "      <td>18.921389</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>45.40</td>\n",
              "      <td>164.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>78.0</td>\n",
              "      <td>36.668167</td>\n",
              "      <td>0</td>\n",
              "      <td>167.6</td>\n",
              "      <td>103.00</td>\n",
              "      <td>282.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>62.0</td>\n",
              "      <td>19.108088</td>\n",
              "      <td>1</td>\n",
              "      <td>157.5</td>\n",
              "      <td>47.40</td>\n",
              "      <td>275.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>73.0</td>\n",
              "      <td>22.851562</td>\n",
              "      <td>0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>58.50</td>\n",
              "      <td>178.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>73.0</td>\n",
              "      <td>20.351971</td>\n",
              "      <td>0</td>\n",
              "      <td>167.5</td>\n",
              "      <td>57.10</td>\n",
              "      <td>159.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>59.0</td>\n",
              "      <td>27.109238</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>85.70</td>\n",
              "      <td>85.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>51.0</td>\n",
              "      <td>37.954367</td>\n",
              "      <td>0</td>\n",
              "      <td>172.7</td>\n",
              "      <td>113.20</td>\n",
              "      <td>168.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>80.0</td>\n",
              "      <td>36.267895</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>117.90</td>\n",
              "      <td>138.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>74.0</td>\n",
              "      <td>25.856081</td>\n",
              "      <td>1</td>\n",
              "      <td>170.2</td>\n",
              "      <td>74.90</td>\n",
              "      <td>145.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>61.0</td>\n",
              "      <td>29.161972</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>94.80</td>\n",
              "      <td>267.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>74.0</td>\n",
              "      <td>38.111136</td>\n",
              "      <td>1</td>\n",
              "      <td>188.0</td>\n",
              "      <td>134.70</td>\n",
              "      <td>279.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>65.0</td>\n",
              "      <td>53.414791</td>\n",
              "      <td>0</td>\n",
              "      <td>166.4</td>\n",
              "      <td>147.90</td>\n",
              "      <td>121.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>38.0</td>\n",
              "      <td>33.438787</td>\n",
              "      <td>0</td>\n",
              "      <td>161.3</td>\n",
              "      <td>87.00</td>\n",
              "      <td>135.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>82.0</td>\n",
              "      <td>32.263238</td>\n",
              "      <td>0</td>\n",
              "      <td>162.6</td>\n",
              "      <td>85.30</td>\n",
              "      <td>111.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8843f732-c893-4db2-bad8-1cdfb52ccdab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8843f732-c893-4db2-bad8-1cdfb52ccdab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8843f732-c893-4db2-bad8-1cdfb52ccdab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global attributes\n",
        "Define the global attributes\n",
        "> Note : You **cannot** modify the values of these attributes we given in the basic part"
      ],
      "metadata": {
        "id": "BhtqUTG9Nlyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = input_data.shape[1] - 1"
      ],
      "metadata": {
        "id": "etfPC94oN_TO"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can add your own global attributes here"
      ],
      "metadata": {
        "id": "V1FN1Z-tOFOo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQ-OYop8ONnv"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Calculate the Entropy and Information Gain \n",
        "Calculate the information gain and entropy values before separate data into left subtree and right subtree"
      ],
      "metadata": {
        "id": "Gey7t_Yx5YML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(data):\n",
        "  \"\"\"\n",
        "  This function measures the amount of uncertainty in a probability distribution\n",
        "  args: \n",
        "  * data(type: DataFrame): the data you're calculating for the entropy\n",
        "  return:\n",
        "  * entropy_value(type: float): the data's entropy\n",
        "  \"\"\"\n",
        "  dia=data['diabetes_mellitus']\n",
        "  n = np.shape(data)[0]\n",
        "  a=dia.value_counts()/n\n",
        "  entropy_value=np.sum(-a*np.log2(a+1e-9))\n",
        "  return entropy_value\n",
        "\n",
        "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
        "ans_entropy = entropy(input_data)\n",
        "print(\"ans_entropy = \", ans_entropy)"
      ],
      "metadata": {
        "id": "hpdNz3ij6keH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd30f346-48e5-4df3-9496-7d6b6833d05c"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_entropy =  0.9871377714867962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(data, mask):\n",
        "  \"\"\"\n",
        "  This function will calculate the information gain\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you're calculating for the information gain\n",
        "  * mask(type: Series): partition information(left/right) of current input data, \n",
        "    - boolean 1(True) represents split to left subtree\n",
        "    - boolean 0(False) represents split to right subtree\n",
        "  return:\n",
        "  * ig(type: float): the information gain you can obtain by classify data with this given mask\n",
        "  \"\"\"\n",
        "  \n",
        "  a=sum(mask)\n",
        "  b=mask.shape[0]-a\n",
        "  \n",
        "  truenum=a/(a+b)\n",
        "  falsenum=b/(a+b)\n",
        "  # if sum(mask)==0 or mask.shape[0]-sum(mask)==0:\n",
        "  #   return 0\n",
        "  if truenum==0 or falsenum==0:\n",
        "    return 0\n",
        "  \n",
        "\n",
        "  if len(data)!=len(mask):\n",
        "     print(\"fuck u\")\n",
        "     print(mask)\n",
        "     print(data)\n",
        "  true_data=data[mask]#true data\n",
        "  false_data=data[-mask]#false data\n",
        "  \n",
        "  \n",
        "  ig=entropy(data)-truenum*entropy(true_data)-falsenum*entropy(false_data)\n",
        "  \n",
        "\n",
        "  return ig\n",
        "\n",
        "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
        "temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)\n",
        "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)\n",
        "temp_mask = np.concatenate((temp1, temp2))\n",
        "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
        "\n",
        "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
        "print(\"ans_informationGain = \", ans_informationGain)"
      ],
      "metadata": {
        "id": "zCC_SiU26kbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac460f3f-5989-401f-8bde-6b0403278a5b"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_informationGain =  0.08345988684807129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Find the Best Split\n",
        "Find the best split combination, **feature** and **threshold**, by calculating the information gain\n"
      ],
      "metadata": {
        "id": "9r8mrn7A55if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maxfind(x,d):\n",
        "  ig=[]\n",
        "  split_value=[]\n",
        "  options = x.sort_values().unique()\n",
        "  for val in options:\n",
        "    mask = (x <= val)\n",
        "    val_ig = information_gain(d,mask)\n",
        "    # Append results\n",
        "    ig.append(val_ig)\n",
        "    split_value.append(val) #分開值\n",
        "  best_ig = max(ig)\n",
        "  best_ig_index = ig.index(best_ig)\n",
        "  best_split = split_value[best_ig_index]\n",
        "  return(best_ig,best_split)\n",
        "  \n",
        "def find_best_split(data):\n",
        "  \"\"\"\n",
        "  This function will find the best split combination of data\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  return\n",
        "  * best_ig(type: float): the best information gain you obtain\n",
        "  * best_threshold(type: float): the value that splits data into 2 branches\n",
        "  * best_feature(type: string): the feature that splits data into 2 branches\n",
        "  \"\"\"\n",
        "  result=data.drop('diabetes_mellitus', axis= 1).apply(maxfind,d=data)\n",
        "  ff=result\n",
        "  ff.index=range(0,2)\n",
        "  #print(ff)\n",
        " \n",
        "  best_ig=ff.max(axis=1)[0]\n",
        "  best_feature=ff.idxmax(axis=1)[0]\n",
        "  best_threshold=result[best_feature][1]\n",
        "  # print(best_threshold)\n",
        "  return best_ig, best_threshold, best_feature\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
        "ans_ig, ans_value, ans_name = find_best_split(input_data)\n",
        "print(\"ans_ig = \", ans_ig)\n",
        "print(\"ans_value = \", ans_value)\n",
        "print(\"ans_name = \", ans_name)"
      ],
      "metadata": {
        "id": "D6gg7ig18XgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c599d949-c27b-456c-ae1d-0f888f6b490a"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_ig =  0.3522950512446044\n",
            "ans_value =  207.0\n",
            "ans_name =  glucose_apache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Split into 2 branches\n",
        "Using the best split combination you find in function *find_best_split()* to split data into Left Subtree and Right Subtree "
      ],
      "metadata": {
        "id": "61hPUYvy6MTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_partition(data, feature, threshold):\n",
        "  \"\"\"\n",
        "  This function will split the data into 2 branches\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  * feature(type: string): the attribute(column name)\n",
        "  * threshold(type: float): the threshold for splitting the data\n",
        "  return:\n",
        "  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
        "  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
        "  \"\"\"\n",
        "  left=data[data[feature]<threshold]\n",
        "  right=data[(data[feature]<threshold)==False]\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  return left, right\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_left\" into the output file\n",
        "left, right = make_partition(input_data, 'age', 61.0)\n",
        "ans_left = left.shape[0]\n",
        "print(\"ans_left = \", ans_left)\n"
      ],
      "metadata": {
        "id": "KQRcjzCLCo4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec382096-b076-402b-a552-19725025e4da"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_left =  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Build Decision Tree\n",
        "Use the above functions to implement the decision tree\n",
        "\n",
        "Instructions: \n",
        "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
        "2.  Use function *find_best_split()* to find the best split combination\n",
        "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
        "4. Use function *make_partition()* to split the data into two parts\n",
        "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLzy6Yhg802x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(data, max_depth, min_samples_split, depth):\n",
        "  \"\"\"\n",
        "  This function will build the decision tree\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you want to apply to the decision tree\n",
        "  * max_depth: the maximum depth of a decision tree\n",
        "  * min_samples_split: the minimum number of instances required to do partition\n",
        "  * depth: the height of the current decision tree\n",
        "  return:\n",
        "  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
        "  \"\"\"\n",
        "  # check the condition of current depth and the remaining number of samples\n",
        "  if depth < max_depth :\n",
        "    # call find_best_split() to find the best combination\n",
        "    split_ig, split_value, split_name=find_best_split(data)\n",
        "    # check the value of information gain is greater than 0 or not \n",
        "    if split_ig > 0 :\n",
        "      # update the depth\n",
        "      depth+=1\n",
        "      # call make_partition() to split the data into two parts\n",
        "      l,r=make_partition(data,split_name,split_value)\n",
        "      # If there is no data split to the left tree OR no data split to the left tree\n",
        "      if l.shape[0]<1 or r.shape[0]<1 :\n",
        "        # return the label of the majority\n",
        "        label = data['diabetes_mellitus'].value_counts().idxmax()\n",
        "        return label\n",
        "      else:\n",
        "        question = \"{} {} {}\".format(split_name, \"<=\", split_value)\n",
        "        subtree = {question: []}\n",
        "\n",
        "        # call function build_tree() to recursively build the left subtree and right subtree\n",
        "        left_subtree = build_tree(l, max_depth, min_samples_split, depth)\n",
        "        right_subtree = build_tree(r, max_depth, min_samples_split, depth)\n",
        "        if left_subtree == right_subtree:\n",
        "          subtree = left_subtree\n",
        "        else:\n",
        "          subtree[question].append(left_subtree)\n",
        "          subtree[question].append(right_subtree)\n",
        "    else:\n",
        "      # return the label of the majority\n",
        "      label =data['diabetes_mellitus'].value_counts().idxmax()\n",
        "      return label\n",
        "  else:\n",
        "    # return the label of the majority\n",
        "    label = data['diabetes_mellitus'].value_counts().idxmax()\n",
        "    return label\n",
        "\n",
        "  return subtree"
      ],
      "metadata": {
        "id": "_OAXVddKkvM2"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output from *build_tree()* \n",
        "```\n",
        "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
        "```\n",
        "Therefore, \n",
        "```\n",
        "ans_features = ['bmi', 'age']\n",
        "ans_thresholds = [33.5, 68.5]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qlIrw9Gu-M9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_features = []\n",
        "ans_thresholds = []\n",
        "\n",
        "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
        "print(decisionTree)\n",
        "treestr=str(decisionTree)\n",
        "string_to_push=\"\"\n",
        "thres_to_push=\"\"\n",
        "for i in treestr:\n",
        "  if i.isalpha() or i==\"_\":\n",
        "    string_to_push+=i\n",
        "  elif i==\" \":\n",
        "    if string_to_push!=\"\":\n",
        "      ans_features.append(string_to_push)\n",
        "      string_to_push=\"\"\n",
        "  elif i.isdigit() or i==\".\":\n",
        "    thres_to_push+=i\n",
        "  elif i=='\\'':\n",
        "    if thres_to_push!=\"\":\n",
        "      ans_thresholds.append(thres_to_push)\n",
        "      thres_to_push=\"\"\n",
        "  else:\n",
        "    thres_to_push=\"\"\n",
        "    string_to_push=\"\"\n",
        "# print(ans_features)\n",
        "# print(ans_thresholds)\n",
        "#list(decisionTree.keys())[0].split()"
      ],
      "metadata": {
        "id": "QW8wm1rD9dlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bf1a05-2fef-4d15-ea75-5a85851048e2"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'glucose_apache <= 207.0': [{'heart_rate_apache <= 133.0': [0, 1]}, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n",
        "ans_features\n"
      ],
      "metadata": {
        "id": "v_n0BfNSGejN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea37e1c-a4d8-4501-8ec0-a48eefc24898"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glucose_apache', 'heart_rate_apache']"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
        "ans_thresholds"
      ],
      "metadata": {
        "id": "D6H9zkN_GgK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221fd190-c09d-4515-aef9-1639806c162f"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['207.0', '133.0']"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step6 : Save answers"
      ],
      "metadata": {
        "id": "rP0SU7tTweOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic = []\n",
        "basic.append(ans_entropy)\n",
        "basic.append(ans_informationGain)\n",
        "basic.append(ans_ig)\n",
        "basic.append(ans_value)\n",
        "basic.append(ans_name)\n",
        "basic.append(ans_left)\n",
        "for i in range(len(ans_features)):\n",
        "  basic.append(ans_features[i])\n",
        "for m in range(len(ans_thresholds)):\n",
        "  basic.append(ans_thresholds[m])"
      ],
      "metadata": {
        "id": "sDO36kKEwh6C"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step7 : Split data\n",
        "Split data into training set and validation set\n",
        "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
      ],
      "metadata": {
        "id": "7DotyrSZjYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 20\n",
        "num_validation = 10\n",
        "\n",
        "training_data = input_data.iloc[:num_train]\n",
        "validation_data = input_data.iloc[-num_validation:]\n",
        "\n",
        "y_train = training_data[[\"diabetes_mellitus\"]] #前20diabetes\n",
        "x_train = training_data.drop(['diabetes_mellitus'], axis=1) #前20參數\n",
        "\n",
        "y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
        "x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
        "\n",
        "y_validation = y_validation.values.flatten()\n",
        "\n",
        "\n",
        "print(input_data.shape)\n",
        "print(training_data.shape)\n",
        "print(validation_data.shape)"
      ],
      "metadata": {
        "id": "WjNM-n4i5mlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf4d2d7-0aef-4a28-945c-ad569f9c6f46"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 10)\n",
            "(20, 10)\n",
            "(10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step8 to Step10 : Make predictions with a decision tree"
      ],
      "metadata": {
        "id": "GfKSt2gH74Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the decision tree\n",
        "> You **cannot** modify the values of these attributes in this part"
      ],
      "metadata": {
        "id": "BZqSVoJ48a3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = x_train.shape[1]"
      ],
      "metadata": {
        "id": "vSlZ7FVB8eau"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished the function '*classify_data()*' below, however, you can modify this function if you prefer completing it on your own way."
      ],
      "metadata": {
        "id": "FrK-YqLmLH8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_data(instance, tree):\n",
        "  \"\"\"\n",
        "  This function will predict/classify the input instance\n",
        "  args:\n",
        "  * instance: a instance(case) to be predicted\n",
        "  return:\n",
        "  * answer: the prediction result (the classification result)\n",
        "  \"\"\"\n",
        "  equation = list(tree.keys())[0] \n",
        "  \n",
        "  if equation.split()[1] == '<=':\n",
        "    temp_feature = equation.split()[0]\n",
        "    temp_threshold = equation.split()[2]\n",
        "    if instance[temp_feature] > float(temp_threshold):\n",
        "      answer = tree[equation][1]\n",
        "    else:\n",
        "      answer = tree[equation][0]\n",
        "  else:\n",
        "    if instance[equation.split()[0]] in (equation.split()[2]):\n",
        "      answer = tree[equation][0]\n",
        "    else:\n",
        "      answer = tree[equation][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    return classify_data(instance, answer)\n",
        "\n",
        "\n",
        "def make_prediction(tree, data):\n",
        "  \"\"\"\n",
        "  This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
        "  args:\n",
        "  * tree: the decision tree\n",
        "  * data: the data to predict\n",
        "  return:\n",
        "  * y_prediction: the predictions\n",
        "  \"\"\"\n",
        "  \n",
        "  # [Note] You can call the function classify_data() to predict the label of each instance\n",
        "  #print(data)\n",
        "  y_prediction=[]\n",
        "  num_obs = len(data)\n",
        " \n",
        "  for i in range(num_obs):\n",
        "    obs_pred = classify_data(data.iloc[i,:], tree)\n",
        "    y_prediction.append(obs_pred)\n",
        "  return y_prediction\n",
        "\n",
        "\n",
        "def calculate_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  This function will calculate the f1-score of the predictions\n",
        "  args:\n",
        "  * y_true: the ground truth\n",
        "  * y_pred: the predictions\n",
        "  return:\n",
        "  * score: the f1-score\n",
        "  \"\"\"\n",
        "  score=f1_score(y_true, y_pred) \n",
        "  return score"
      ],
      "metadata": {
        "id": "0piZ0blpFXVq"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
        "\n",
        "y_pred = make_prediction(decision_tree, x_validation)\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" the your output file\n",
        "ans_f1score = calculate_score(y_validation, y_pred)\n",
        "print(\"ans_f1score = \", ans_f1score)"
      ],
      "metadata": {
        "id": "3IEu3z3s9TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0be3ed4-8d9a-4582-986d-8624a3ed149f"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_f1score =  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step11 : Write the Output File\n",
        "Save all of your answers in a csv file, named as **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "IzzOKOwn-kod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_path = 'hw2_basic.csv'\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" into the output file\n",
        "basic.append(ans_f1score)\n",
        "print(basic)\n",
        "\n",
        "pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "p0zsaWPL2qXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78f82b5-a2fb-4f3b-bd36-e84ffa981ddc"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9871377714867962, 0.08345988684807129, 0.3522950512446044, 207.0, 'glucose_apache', 9, 'glucose_apache', 'heart_rate_apache', '207.0', '133.0', 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Part** (35%)"
      ],
      "metadata": {
        "id": "tV25IjM7_aEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_advanced.csv**"
      ],
      "metadata": {
        "id": "knH1Ih0Pha7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_data = pd.read_csv('hw2_input_advanced.csv')"
      ],
      "metadata": {
        "id": "FthBdLxRhi9W"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can split *advanced_data* into training set and validaiton set"
      ],
      "metadata": {
        "id": "vqLH49oBndRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = int(8379*2/3)\n",
        "num_validation = int(8379/3)\n",
        "\n",
        "training_data = advanced_data.iloc[:num_train]\n",
        "validation_data = advanced_data.iloc[-num_validation:]\n",
        "\n",
        "validy = validation_data[[\"diabetes_mellitus\"]]\n",
        "validx = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "9l0hLPVjncam"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Load the test data\n",
        "Load the input file **hw2_input_test.csv** to make predictions with the pre-trained random forest model"
      ],
      "metadata": {
        "id": "tFgbUY_ajVOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('hw2_input_test.csv')\n",
        "x_test"
      ],
      "metadata": {
        "id": "3hW542KWNxVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ca146ef-6660-4a08-b5c0-db81743e78e8"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age        bmi  gender  height  weight  arf_apache  bun_apache  \\\n",
              "0     62  32.866392       1  177.80   103.9           1        31.0   \n",
              "1     82  23.582766       0  157.50    58.5           0        26.0   \n",
              "2     61  31.684520       1  172.70    94.5           0        16.0   \n",
              "3     58  45.156250       0  160.00   115.6           0        19.0   \n",
              "4     74  25.817016       1  172.70    77.0           0        25.0   \n",
              "..   ...        ...     ...     ...     ...         ...         ...   \n",
              "835   73  17.943584       0  157.48    44.5           0        12.0   \n",
              "836   79  29.049732       1  167.60    81.6           0        48.0   \n",
              "837   85  24.627827       0  152.40    57.2           0        11.0   \n",
              "838   68  32.510940       1  193.00   121.1           0        14.0   \n",
              "839   48  24.106828       0  157.50    59.8           0         7.0   \n",
              "\n",
              "     creatinine_apache  gcs_eyes_apache  gcs_motor_apache  ...  \\\n",
              "0                10.30                4                 6  ...   \n",
              "1                 0.54                3                 4  ...   \n",
              "2                 1.11                4                 6  ...   \n",
              "3                 0.70                1                 4  ...   \n",
              "4                 0.93                4                 6  ...   \n",
              "..                 ...              ...               ...  ...   \n",
              "835               0.30                4                 6  ...   \n",
              "836               2.19                4                 6  ...   \n",
              "837               0.48                3                 5  ...   \n",
              "838               0.64                4                 6  ...   \n",
              "839               0.33                4                 6  ...   \n",
              "\n",
              "     hematocrit_apache  intubated_apache  map_apache  resprate_apache  \\\n",
              "0                 36.4                 0         157               26   \n",
              "1                 32.8                 0          42               25   \n",
              "2                 35.3                 0         129                6   \n",
              "3                 30.1                 1         131               23   \n",
              "4                 34.5                 0          55               12   \n",
              "..                 ...               ...         ...              ...   \n",
              "835               33.8                 0         129                9   \n",
              "836               42.7                 0         163                9   \n",
              "837               29.5                 0          67                9   \n",
              "838               37.5                 0          61               10   \n",
              "839               32.3                 0         111               14   \n",
              "\n",
              "     sodium_apache  temp_apache  ventilated_apache  wbc_apache  \\\n",
              "0              134         36.1                  0        4.56   \n",
              "1              142         36.1                  0        6.00   \n",
              "2              131         36.8                  0        8.59   \n",
              "3              138         34.9                  1       16.03   \n",
              "4              135         36.3                  0       45.80   \n",
              "..             ...          ...                ...         ...   \n",
              "835            144         36.9                  0        7.70   \n",
              "836            139         36.4                  0       10.77   \n",
              "837            139         36.6                  0        7.35   \n",
              "838            140         36.9                  1       16.02   \n",
              "839            139         36.3                  0        2.20   \n",
              "\n",
              "     apache_4a_hospital_death_prob  apache_4a_icu_death_prob  \n",
              "0                             0.06                      0.03  \n",
              "1                             0.14                      0.06  \n",
              "2                             0.05                      0.03  \n",
              "3                             0.33                      0.22  \n",
              "4                             0.12                      0.05  \n",
              "..                             ...                       ...  \n",
              "835                           0.02                      0.01  \n",
              "836                           0.06                      0.03  \n",
              "837                           0.16                      0.05  \n",
              "838                           0.00                      0.00  \n",
              "839                           0.01                      0.00  \n",
              "\n",
              "[840 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5ece979-b1bc-43e5-bb84-5acfa76f7e7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>arf_apache</th>\n",
              "      <th>bun_apache</th>\n",
              "      <th>creatinine_apache</th>\n",
              "      <th>gcs_eyes_apache</th>\n",
              "      <th>gcs_motor_apache</th>\n",
              "      <th>...</th>\n",
              "      <th>hematocrit_apache</th>\n",
              "      <th>intubated_apache</th>\n",
              "      <th>map_apache</th>\n",
              "      <th>resprate_apache</th>\n",
              "      <th>sodium_apache</th>\n",
              "      <th>temp_apache</th>\n",
              "      <th>ventilated_apache</th>\n",
              "      <th>wbc_apache</th>\n",
              "      <th>apache_4a_hospital_death_prob</th>\n",
              "      <th>apache_4a_icu_death_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62</td>\n",
              "      <td>32.866392</td>\n",
              "      <td>1</td>\n",
              "      <td>177.80</td>\n",
              "      <td>103.9</td>\n",
              "      <td>1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>10.30</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>36.4</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>26</td>\n",
              "      <td>134</td>\n",
              "      <td>36.1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>23.582766</td>\n",
              "      <td>0</td>\n",
              "      <td>157.50</td>\n",
              "      <td>58.5</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>32.8</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>25</td>\n",
              "      <td>142</td>\n",
              "      <td>36.1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61</td>\n",
              "      <td>31.684520</td>\n",
              "      <td>1</td>\n",
              "      <td>172.70</td>\n",
              "      <td>94.5</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.11</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>6</td>\n",
              "      <td>131</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0</td>\n",
              "      <td>8.59</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>45.156250</td>\n",
              "      <td>0</td>\n",
              "      <td>160.00</td>\n",
              "      <td>115.6</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>30.1</td>\n",
              "      <td>1</td>\n",
              "      <td>131</td>\n",
              "      <td>23</td>\n",
              "      <td>138</td>\n",
              "      <td>34.9</td>\n",
              "      <td>1</td>\n",
              "      <td>16.03</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74</td>\n",
              "      <td>25.817016</td>\n",
              "      <td>1</td>\n",
              "      <td>172.70</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.93</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>135</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>73</td>\n",
              "      <td>17.943584</td>\n",
              "      <td>0</td>\n",
              "      <td>157.48</td>\n",
              "      <td>44.5</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>33.8</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>9</td>\n",
              "      <td>144</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>79</td>\n",
              "      <td>29.049732</td>\n",
              "      <td>1</td>\n",
              "      <td>167.60</td>\n",
              "      <td>81.6</td>\n",
              "      <td>0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>2.19</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>42.7</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "      <td>139</td>\n",
              "      <td>36.4</td>\n",
              "      <td>0</td>\n",
              "      <td>10.77</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>85</td>\n",
              "      <td>24.627827</td>\n",
              "      <td>0</td>\n",
              "      <td>152.40</td>\n",
              "      <td>57.2</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>29.5</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>9</td>\n",
              "      <td>139</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>68</td>\n",
              "      <td>32.510940</td>\n",
              "      <td>1</td>\n",
              "      <td>193.00</td>\n",
              "      <td>121.1</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>37.5</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>10</td>\n",
              "      <td>140</td>\n",
              "      <td>36.9</td>\n",
              "      <td>1</td>\n",
              "      <td>16.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>48</td>\n",
              "      <td>24.106828</td>\n",
              "      <td>0</td>\n",
              "      <td>157.50</td>\n",
              "      <td>59.8</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>32.3</td>\n",
              "      <td>0</td>\n",
              "      <td>111</td>\n",
              "      <td>14</td>\n",
              "      <td>139</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>840 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5ece979-b1bc-43e5-bb84-5acfa76f7e7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5ece979-b1bc-43e5-bb84-5acfa76f7e7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5ece979-b1bc-43e5-bb84-5acfa76f7e7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Build a Random Forest"
      ],
      "metadata": {
        "id": "mH-0DxyR9qWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the random forest\n",
        "> * You **can** modify the values of these attributes in advanced part\n",
        "> * Each tree can have different attribute values\n",
        "> * There must be **at least** 3 decision trees in the random forest model\n",
        "> * Must use function *build_tree()* to build a random forest model\n",
        "> * These are the parameters you can adjust : \n",
        "\n",
        "\n",
        "    ```\n",
        "    max_depth = \n",
        "    depth = 0\n",
        "    min_samples_split = \n",
        "    \n",
        "    # total number of trees in a random forest\n",
        "    n_trees = \n",
        "\n",
        "    # number of features to train a decision tree\n",
        "    n_features = \n",
        "\n",
        "    # the ratio to select the number of instances\n",
        "    sample_size = \n",
        "    n_samples = int(training_data.shape[0] * sample_size)\n",
        "    ```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xbLxFW597FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the attributes\n",
        "\n",
        "max_depth = 7\n",
        "depth = 0\n",
        "min_samples_split = 11\n",
        "    \n",
        "# total number of trees in a random forest\n",
        "n_trees = 15\n",
        "\n",
        "# number of features to train a decision tree\n",
        "n_features = 11\n",
        "\n",
        "# the ratio to select the number of instances\n",
        "sample_size = 0.25\n",
        "n_samples = int(training_data.shape[0] * sample_size)\n"
      ],
      "metadata": {
        "id": "LD8ndJ8ymzG3"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data\n"
      ],
      "metadata": {
        "id": "C2MYXuPJY3Wl"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_forest(data, n_trees, n_features, n_samples):\n",
        "  \"\"\"\n",
        "  This function will build a random forest.\n",
        "  args:\n",
        "  * data: all data that can be used to train a random forest\n",
        "  * n_trees: total number of tree\n",
        "  * n_features: number of features\n",
        "  * n_samples: number of instances\n",
        "  return:\n",
        "  * forest: a random forest with 'n_trees' of decision tree\n",
        "  \"\"\"\n",
        "  drop_num=24-n_features #13\n",
        "  all_features=[]\n",
        "  for i in data:\n",
        "    all_features.append(i)\n",
        "  all_features.pop()\n",
        "  \n",
        "  forest=[]\n",
        "  for i in range(0, n_trees):\n",
        "    drop_idxs=random.randrange(0, len(all_features), drop_num)\n",
        "    drop_list=[]\n",
        "    \n",
        "    for idx in range(drop_num):\n",
        "      drop_list.append(all_features[idx])\n",
        "\n",
        "    # print(drop_list)\n",
        "    tmp=data.drop(drop_list,axis=1)\n",
        "    # print(drop_list)\n",
        "    # print(tmp)\n",
        "    # bootstrap training dataset\n",
        "    #\n",
        "    sample=data.sample(n_samples)\n",
        "    tree=build_tree(sample, max_depth, 2,0)\n",
        "    #k_indices = np.random.choice(len(data), 10)\n",
        "    print(tree)\n",
        "    forest.append(tree)\n",
        "  # must reuse function build_tree()\n",
        "  #tree = build_tree(.....)\n",
        "\n",
        "  return forest"
      ],
      "metadata": {
        "id": "hVl66f1aU36-"
      },
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest = build_forest(advanced_data, n_trees, n_features, n_samples)"
      ],
      "metadata": {
        "id": "zylo6C51m3OJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b4dfbe-5a5b-4627-fce4-f4e1637a959a"
      },
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'glucose_apache <= 162.0': [{'age <= 50.0': [{'bmi <= 31.65185643': [0, {'glucose_apache <= 73.0': [1, {'resprate_apache <= 13.0': [{'bun_apache <= 27.0': [{'glucose_apache <= 141.0': [0, 1]}, 1]}, 0]}]}]}, {'weight <= 99.8': [{'resprate_apache <= 13.0': [{'bun_apache <= 43.0': [0, {'age <= 81.0': [1, 0]}]}, {'glucose_apache <= 87.0': [{'apache_4a_hospital_death_prob <= 0.01': [1, 0]}, 0]}]}, {'hematocrit_apache <= 34.4': [{'gcs_verbal_apache <= 2.0': [1, {'bmi <= 38.20018365': [{'resprate_apache <= 30.0': [1, 0]}, 1]}]}, {'age <= 58.0': [0, {'glucose_apache <= 87.0': [{'sodium_apache <= 132.0': [0, 1]}, 0]}]}]}]}]}, {'glucose_apache <= 213.0': [{'resprate_apache <= 12.0': [{'map_apache <= 121.0': [{'temp_apache <= 34.4': [0, 1]}, 1]}, {'bmi <= 22.88729234': [{'bun_apache <= 60.0': [0, 1]}, {'age <= 35.0': [0, 1]}]}]}, {'wbc_apache <= 24.2': [{'apache_4a_icu_death_prob <= 0.13': [1, {'resprate_apache <= 38.0': [1, {'wbc_apache <= 5.1': [1, 0]}]}]}, {'glucose_apache <= 257.0': [{'map_apache <= 61.0': [{'age <= 64.0': [1, 0]}, 0]}, {'bmi <= 26.02429118': [0, {'heart_rate_apache <= 95.0': [0, {'creatinine_apache <= 3.24': [1, 0]}]}]}]}]}]}]}\n",
            "{'glucose_apache <= 179.0': [{'age <= 52.0': [{'hematocrit_apache <= 29.8': [{'gcs_verbal_apache <= 2.0': [{'resprate_apache <= 35.0': [1, 0]}, {'glucose_apache <= 165.0': [0, {'age <= 45.0': [1, 0]}]}]}, {'age <= 36.0': [0, {'map_apache <= 72.0': [{'wbc_apache <= 5.8': [1, 0]}, 0]}]}]}, 0]}, {'resprate_apache <= 33.0': [{'glucose_apache <= 216.0': [{'height <= 182.8': [{'bmi <= 33.21183432': [{'heart_rate_apache <= 122.0': [1, 0]}, {'age <= 79.0': [1, 0]}]}, {'age <= 59.0': [0, {'bun_apache <= 29.0': [1, {'gcs_eyes_apache <= 2.0': [1, 0]}]}]}]}, {'gcs_motor_apache <= 4.0': [{'map_apache <= 117.0': [{'sodium_apache <= 139.0': [{'height <= 170.0': [1, 0]}, {'glucose_apache <= 392.0': [1, 0]}]}, 1]}, 1]}]}, {'glucose_apache <= 262.0': [0, {'resprate_apache <= 35.0': [1, {'weight <= 55.29': [{'resprate_apache <= 37.0': [1, 0]}, {'hematocrit_apache <= 34.3': [1, {'apache_4a_hospital_death_prob <= 0.11': [1, 0]}]}]}]}]}]}]}\n",
            "{'glucose_apache <= 168.0': [{'glucose_apache <= 74.0': [{'age <= 58.0': [{'wbc_apache <= 5.2': [1, 0]}, {'apache_4a_icu_death_prob <= 0.11': [{'bmi <= 20.51474691': [0, {'heart_rate_apache <= 123.0': [{'bun_apache <= 121.0': [1, 0]}, {'glucose_apache <= 56.0': [1, 0]}]}]}, {'hematocrit_apache <= 36.2': [{'resprate_apache <= 48.0': [{'glucose_apache <= 45.0': [1, 0]}, 1]}, 1]}]}]}, {'resprate_apache <= 13.0': [{'age <= 38.0': [0, {'bmi <= 23.79426809': [0, {'bun_apache <= 13.0': [{'wbc_apache <= 6.9': [1, 0]}, {'age <= 78.0': [1, 0]}]}]}]}, 0]}]}, {'resprate_apache <= 15.0': [1, {'glucose_apache <= 220.0': [{'age <= 41.0': [0, 1]}, {'gcs_motor_apache <= 4.0': [{'wbc_apache <= 19.4': [{'age <= 64.0': [{'apache_4a_hospital_death_prob <= 0.6': [1, 0]}, 1]}, {'bmi <= 47.39706242': [0, 1]}]}, 1]}]}]}]}\n",
            "{'glucose_apache <= 163.0': [{'age <= 50.0': [{'wbc_apache <= 8.8': [{'resprate_apache <= 8.0': [{'bun_apache <= 11.0': [0, 1]}, {'sodium_apache <= 142.0': [{'height <= 180.3': [0, {'hematocrit_apache <= 29.8': [1, 0]}]}, {'glucose_apache <= 105.0': [0, 1]}]}]}, {'weight <= 127.0': [0, {'age <= 44.0': [0, 1]}]}]}, 0]}, {'resprate_apache <= 34.0': [{'apache_4a_hospital_death_prob <= 0.25': [{'hematocrit_apache <= 50.1': [{'glucose_apache <= 271.0': [{'map_apache <= 51.0': [{'wbc_apache <= 6.6': [0, 1]}, 1]}, 1]}, {'bmi <= 41.23960695': [0, 1]}]}, {'hematocrit_apache <= 37.3': [{'bun_apache <= 31.0': [{'bun_apache <= 14.0': [1, 0]}, {'resprate_apache <= 15.0': [1, {'glucose_apache <= 231.0': [0, 1]}]}]}, 0]}]}, {'glucose_apache <= 234.0': [{'gcs_verbal_apache <= 4.0': [{'bmi <= 32.25450616': [{'height <= 167.6': [0, 1]}, 1]}, {'hematocrit_apache <= 25.5': [0, {'apache_4a_icu_death_prob <= 0.19': [0, 1]}]}]}, {'resprate_apache <= 49.0': [{'glucose_apache <= 253.0': [1, {'heart_rate_apache <= 143.0': [{'heart_rate_apache <= 120.0': [1, 0]}, 1]}]}, {'heart_rate_apache <= 124.0': [{'hematocrit_apache <= 30.1': [1, {'temp_apache <= 35.9': [0, 1]}]}, {'resprate_apache <= 50.0': [1, {'bmi <= 33.77635341': [0, 1]}]}]}]}]}]}]}\n",
            "{'glucose_apache <= 164.0': [{'age <= 45.0': [{'resprate_apache <= 13.0': [{'heart_rate_apache <= 105.0': [{'age <= 36.0': [0, {'height <= 177.8': [{'age <= 41.0': [1, 0]}, 0]}]}, {'weight <= 131.5': [0, 1]}]}, {'glucose_apache <= 105.0': [0, {'height <= 182.9': [0, 1]}]}]}, 0]}, {'resprate_apache <= 27.0': [{'glucose_apache <= 186.0': [{'height <= 180.0': [{'heart_rate_apache <= 103.0': [1, {'bmi <= 22.96708599': [0, 1]}]}, {'heart_rate_apache <= 104.0': [0, {'glucose_apache <= 169.0': [0, {'age <= 87.0': [1, 0]}]}]}]}, {'apache_4a_hospital_death_prob <= 0.3': [{'hematocrit_apache <= 42.7': [1, {'gcs_verbal_apache <= 4.0': [1, {'map_apache <= 69.0': [0, 1]}]}]}, {'sodium_apache <= 137.0': [{'hematocrit_apache <= 31.8': [{'hematocrit_apache <= 25.4': [0, 1]}, {'age <= 76.0': [0, 1]}]}, 1]}]}]}, {'glucose_apache <= 219.0': [{'wbc_apache <= 6.83': [{'heart_rate_apache <= 127.0': [{'height <= 187.96': [1, 0]}, {'bun_apache <= 41.0': [0, 1]}]}, {'bmi <= 26.13239536': [0, {'resprate_apache <= 35.0': [{'age <= 48.0': [0, 1]}, {'temp_apache <= 35.7': [1, 0]}]}]}]}, {'creatinine_apache <= 1.59': [{'sodium_apache <= 149.0': [{'hematocrit_apache <= 27.1': [1, {'hematocrit_apache <= 42.4': [1, 0]}]}, 0]}, {'height <= 160.02': [{'age <= 63.0': [{'bun_apache <= 25.0': [0, 1]}, 1]}, {'resprate_apache <= 48.0': [{'wbc_apache <= 20.5': [0, 1]}, 0]}]}]}]}]}]}\n",
            "{'glucose_apache <= 164.0': [{'bmi <= 29.35516075': [{'resprate_apache <= 13.0': [0, {'glucose_apache <= 86.0': [{'bmi <= 22.59156575': [{'glucose_apache <= 82.0': [0, {'bun_apache <= 33.0': [0, 1]}]}, 0]}, 0]}]}, {'glucose_apache <= 89.0': [{'bun_apache <= 58.0': [{'hematocrit_apache <= 25.5': [1, {'bmi <= 38.80666113': [{'wbc_apache <= 10.1': [0, 1]}, 1]}]}, {'hematocrit_apache <= 23.3': [1, 0]}]}, 0]}]}, {'glucose_apache <= 208.0': [{'resprate_apache <= 27.0': [{'creatinine_apache <= 0.83': [{'apache_4a_icu_death_prob <= 0.04': [{'bmi <= 23.33218028': [0, {'apache_4a_hospital_death_prob <= 0.02': [0, 1]}]}, {'glucose_apache <= 191.0': [1, {'height <= 167.6': [0, 1]}]}]}, {'weight <= 109.3': [{'wbc_apache <= 6.1': [1, {'height <= 185.4': [1, 0]}]}, 1]}]}, 0]}, {'resprate_apache <= 33.0': [{'wbc_apache <= 16.2': [{'hematocrit_apache <= 44.0': [{'apache_4a_hospital_death_prob <= 0.5': [1, {'bmi <= 29.4022733': [1, 0]}]}, {'map_apache <= 120.0': [1, 0]}]}, {'sodium_apache <= 131.0': [1, {'bun_apache <= 27.0': [1, {'apache_4a_hospital_death_prob <= 0.35': [1, 0]}]}]}]}, {'wbc_apache <= 27.1': [{'weight <= 55.29': [{'temp_apache <= 35.8': [1, 0]}, {'glucose_apache <= 218.0': [{'bmi <= 32.25450616': [0, 1]}, 1]}]}, 0]}]}]}]}\n",
            "{'glucose_apache <= 170.0': [{'age <= 38.0': [{'apache_4a_icu_death_prob <= 0.15': [0, {'bmi <= 33.56401384': [0, 1]}]}, {'resprate_apache <= 15.0': [{'glucose_apache <= 85.0': [{'sodium_apache <= 132.0': [{'weight <= 65.9': [1, 0]}, 1]}, {'heart_rate_apache <= 102.0': [{'hematocrit_apache <= 31.8': [1, 0]}, 0]}]}, {'glucose_apache <= 78.0': [{'bmi <= 28.09529199': [{'weight <= 82.7': [{'sodium_apache <= 130.0': [1, 0]}, 1]}, {'bun_apache <= 46.0': [{'hematocrit_apache <= 38.5': [1, 0]}, {'creatinine_apache <= 3.88': [0, 1]}]}]}, {'weight <= 85.0': [{'hematocrit_apache <= 33.6': [{'glucose_apache <= 165.0': [0, 1]}, 0]}, {'age <= 62.0': [{'temp_apache <= 36.1': [1, 0]}, {'resprate_apache <= 33.0': [1, 0]}]}]}]}]}]}, {'resprate_apache <= 34.0': [{'glucose_apache <= 199.0': [{'apache_4a_hospital_death_prob <= 0.02': [1, {'age <= 49.0': [0, {'sodium_apache <= 131.0': [0, 1]}]}]}, {'heart_rate_apache <= 91.0': [1, {'map_apache <= 150.0': [{'heart_rate_apache <= 147.0': [1, {'resprate_apache <= 26.0': [0, 1]}]}, 1]}]}]}, {'bun_apache <= 20.0': [{'heart_rate_apache <= 62.0': [0, {'apache_4a_hospital_death_prob <= 0.01': [1, 0]}]}, {'glucose_apache <= 213.0': [{'gcs_verbal_apache <= 3.0': [{'temp_apache <= 36.8': [1, {'map_apache <= 57.0': [0, 1]}]}, {'age <= 58.0': [{'bun_apache <= 45.0': [0, 1]}, {'height <= 167.64': [1, 0]}]}]}, {'gcs_motor_apache <= 4.0': [{'bun_apache <= 32.0': [0, {'bmi <= 37.52493507': [0, 1]}]}, 1]}]}]}]}]}\n",
            "{'glucose_apache <= 175.0': [{'age <= 51.0': [{'bun_apache <= 22.0': [0, {'map_apache <= 122.0': [{'weight <= 68.6': [0, {'sodium_apache <= 136.0': [{'bun_apache <= 41.0': [0, 1]}, 1]}]}, 0]}]}, {'resprate_apache <= 11.0': [{'glucose_apache <= 75.0': [1, {'glucose_apache <= 141.0': [{'temp_apache <= 35.4': [1, {'creatinine_apache <= 1.48': [0, 1]}]}, {'heart_rate_apache <= 101.0': [{'map_apache <= 60.0': [1, 0]}, 1]}]}]}, {'glucose_apache <= 86.0': [{'bmi <= 24.39286138': [{'apache_4a_hospital_death_prob <= 0.31': [0, {'glucose_apache <= 74.0': [1, 0]}]}, {'temp_apache <= 36.61': [{'glucose_apache <= 78.0': [1, 0]}, {'resprate_apache <= 41.0': [1, 0]}]}]}, {'hematocrit_apache <= 36.1': [{'resprate_apache <= 28.0': [{'heart_rate_apache <= 112.0': [1, 0]}, {'temp_apache <= 36.1': [1, 0]}]}, 0]}]}]}]}, {'glucose_apache <= 208.0': [{'resprate_apache <= 29.0': [{'heart_rate_apache <= 104.0': [{'age <= 53.0': [{'height <= 182.88': [0, 1]}, 1]}, {'map_apache <= 143.0': [{'wbc_apache <= 6.4': [0, 1]}, 0]}]}, 0]}, {'wbc_apache <= 20.5': [{'heart_rate_apache <= 125.0': [1, {'gcs_motor_apache <= 4.0': [0, {'age <= 64.0': [{'apache_4a_hospital_death_prob <= 0.04': [1, 0]}, 1]}]}]}, {'glucose_apache <= 335.0': [0, {'glucose_apache <= 508.0': [1, {'height <= 170.0': [1, {'resprate_apache <= 39.0': [0, 1]}]}]}]}]}]}]}\n",
            "{'glucose_apache <= 171.0': [{'age <= 51.0': [{'bmi <= 41.97259072': [{'age <= 36.0': [0, {'hematocrit_apache <= 23.9': [0, {'height <= 157.0': [{'bmi <= 31.77506355': [0, 1]}, 0]}]}]}, {'sodium_apache <= 135.0': [1, {'weight <= 144.4': [{'hematocrit_apache <= 32.4': [1, 0]}, 0]}]}]}, {'resprate_apache <= 33.0': [{'glucose_apache <= 68.0': [{'glucose_apache <= 45.0': [{'bun_apache <= 47.0': [0, 1]}, {'bun_apache <= 69.0': [1, 0]}]}, 0]}, 0]}]}, {'resprate_apache <= 36.0': [{'glucose_apache <= 199.0': [{'bun_apache <= 61.0': [{'weight <= 120.2': [{'weight <= 65.0': [{'wbc_apache <= 10.9': [0, 1]}, 1]}, {'age <= 51.0': [0, 1]}]}, {'age <= 74.0': [0, 1]}]}, {'height <= 162.5': [{'apache_4a_icu_death_prob <= 0.1': [1, {'glucose_apache <= 259.0': [{'creatinine_apache <= 1.35': [0, 1]}, 1]}]}, {'creatinine_apache <= 0.99': [1, {'weight <= 130.7': [{'hematocrit_apache <= 40.2': [1, 0]}, 1]}]}]}]}, {'glucose_apache <= 240.0': [{'heart_rate_apache <= 52.0': [1, {'age <= 70.0': [{'bmi <= 31.8853431': [0, {'temp_apache <= 36.33': [1, 0]}]}, {'resprate_apache <= 43.0': [{'bun_apache <= 15.0': [1, 0]}, {'heart_rate_apache <= 124.0': [1, 0]}]}]}]}, {'age <= 65.0': [{'resprate_apache <= 58.0': [{'bmi <= 20.38538435': [0, {'resprate_apache <= 54.0': [1, 0]}]}, {'height <= 172.72': [0, 1]}]}, {'sodium_apache <= 147.0': [{'weight <= 108.8': [1, {'heart_rate_apache <= 104.0': [1, 0]}]}, 0]}]}]}]}]}\n",
            "{'glucose_apache <= 193.0': [{'resprate_apache <= 29.0': [{'age <= 52.0': [{'bmi <= 22.77862791': [0, {'hematocrit_apache <= 29.5': [{'heart_rate_apache <= 112.0': [1, 0]}, {'glucose_apache <= 165.0': [0, {'height <= 170.8': [1, 0]}]}]}]}, {'glucose_apache <= 159.0': [{'hematocrit_apache <= 33.2': [{'gcs_verbal_apache <= 4.0': [{'sodium_apache <= 135.0': [0, 1]}, {'resprate_apache <= 22.0': [0, 1]}]}, {'creatinine_apache <= 0.67': [{'resprate_apache <= 11.0': [0, 1]}, {'weight <= 119.7': [0, 1]}]}]}, {'bmi <= 20.96245906': [0, {'heart_rate_apache <= 132.0': [{'height <= 192.0': [1, 0]}, {'age <= 77.0': [1, 0]}]}]}]}]}, {'glucose_apache <= 78.0': [{'bmi <= 27.61664234': [{'glucose_apache <= 69.0': [{'bun_apache <= 7.0': [1, 0]}, 0]}, {'age <= 69.0': [{'bmi <= 39.50926269': [{'age <= 54.0': [0, 1]}, 1]}, 1]}]}, {'glucose_apache <= 176.0': [0, {'bun_apache <= 18.0': [{'age <= 70.0': [0, 1]}, {'age <= 81.0': [{'temp_apache <= 36.0': [1, 0]}, 1]}]}]}]}]}, {'resprate_apache <= 34.0': [{'glucose_apache <= 216.0': [{'wbc_apache <= 12.9': [1, {'creatinine_apache <= 1.3': [{'map_apache <= 64.0': [1, {'age <= 62.0': [0, 1]}]}, 0]}]}, {'apache_4a_hospital_death_prob <= 0.01': [1, {'bun_apache <= 22.0': [1, {'map_apache <= 163.0': [1, {'glucose_apache <= 291.0': [0, 1]}]}]}]}]}, {'weight <= 51.9': [0, {'creatinine_apache <= 0.74': [1, {'age <= 66.0': [{'hematocrit_apache <= 25.1': [0, {'map_apache <= 135.0': [1, 0]}]}, {'temp_apache <= 32.2': [0, 1]}]}]}]}]}]}\n",
            "{'glucose_apache <= 164.0': [{'resprate_apache <= 13.0': [{'hematocrit_apache <= 29.7': [{'heart_rate_apache <= 112.0': [{'hematocrit_apache <= 21.5': [1, {'creatinine_apache <= 2.23': [{'glucose_apache <= 154.0': [0, 1]}, 1]}]}, 0]}, {'apache_4a_hospital_death_prob <= 0.03': [{'map_apache <= 143.0': [{'sodium_apache <= 140.0': [{'temp_apache <= 37.8': [0, 1]}, 0]}, 1]}, {'weight <= 117.4': [0, 1]}]}]}, {'age <= 51.0': [{'glucose_apache <= 54.0': [{'age <= 45.0': [1, 0]}, 0]}, {'weight <= 63.51': [{'wbc_apache <= 24.5': [0, {'bmi <= 19.80208042': [0, 1]}]}, {'height <= 162.56': [{'heart_rate_apache <= 54.0': [0, {'apache_4a_hospital_death_prob <= 0.01': [0, 1]}]}, {'glucose_apache <= 80.0': [{'age <= 56.0': [0, 1]}, 0]}]}]}]}]}, {'resprate_apache <= 36.0': [{'glucose_apache <= 208.0': [{'wbc_apache <= 12.5': [{'age <= 86.0': [1, 0]}, {'age <= 42.0': [0, {'gcs_motor_apache <= 5.0': [{'map_apache <= 47.0': [0, 1]}, 0]}]}]}, {'gcs_motor_apache <= 4.0': [{'bmi <= 35.1017595': [{'bun_apache <= 13.0': [0, {'glucose_apache <= 434.0': [1, 0]}]}, {'age <= 74.0': [1, 0]}]}, 1]}]}, {'glucose_apache <= 257.0': [{'age <= 62.0': [{'hematocrit_apache <= 44.3': [{'weight <= 112.9': [0, {'height <= 175.3': [0, 1]}]}, 1]}, {'heart_rate_apache <= 69.0': [1, {'bmi <= 26.13239536': [0, {'hematocrit_apache <= 40.2': [1, 0]}]}]}]}, {'sodium_apache <= 149.0': [{'age <= 61.0': [{'temp_apache <= 37.0': [{'sodium_apache <= 134.0': [0, 1]}, 1]}, {'bun_apache <= 16.0': [{'heart_rate_apache <= 96.0': [1, 0]}, 1]}]}, 0]}]}]}]}\n",
            "{'glucose_apache <= 174.0': [{'resprate_apache <= 15.0': [{'age <= 55.0': [{'glucose_apache <= 60.0': [1, {'creatinine_apache <= 0.44': [1, {'glucose_apache <= 160.0': [0, {'age <= 36.0': [0, 1]}]}]}]}, {'wbc_apache <= 3.0': [0, {'bmi <= 35.34868181': [{'glucose_apache <= 69.0': [{'gcs_eyes_apache <= 3.0': [0, 1]}, 0]}, {'age <= 70.0': [{'height <= 157.5': [0, 1]}, 1]}]}]}]}, {'creatinine_apache <= 2.71': [{'age <= 70.0': [{'hematocrit_apache <= 28.0': [{'bmi <= 34.49962455': [0, {'resprate_apache <= 32.0': [1, 0]}]}, 0]}, {'bmi <= 23.01777361': [0, {'sodium_apache <= 132.0': [0, {'glucose_apache <= 85.0': [1, 0]}]}]}]}, {'wbc_apache <= 8.3': [1, {'bmi <= 31.72786022': [{'heart_rate_apache <= 135.0': [{'temp_apache <= 35.0': [1, 0]}, 1]}, {'resprate_apache <= 41.0': [1, {'wbc_apache <= 9.2': [1, 0]}]}]}]}]}]}, {'resprate_apache <= 41.0': [{'glucose_apache <= 215.0': [{'resprate_apache <= 14.0': [{'heart_rate_apache <= 115.0': [{'bmi <= 21.7578125': [0, {'hematocrit_apache <= 46.7': [1, 0]}]}, {'weight <= 90.4': [{'hematocrit_apache <= 26.3': [1, 0]}, 1]}]}, {'creatinine_apache <= 3.3': [{'apache_4a_hospital_death_prob <= 0.37': [{'bmi <= 21.94762454': [0, 1]}, 0]}, 1]}]}, {'gcs_motor_apache <= 4.0': [{'bun_apache <= 15.0': [0, {'height <= 175.2': [{'map_apache <= 164.0': [1, 0]}, {'bun_apache <= 16.0': [0, 1]}]}]}, 1]}]}, {'wbc_apache <= 23.8': [{'glucose_apache <= 183.0': [0, {'wbc_apache <= 3.3': [0, {'age <= 82.0': [{'apache_4a_icu_death_prob <= 0.47': [1, 0]}, 1]}]}]}, {'temp_apache <= 36.5': [0, 1]}]}]}]}\n",
            "{'glucose_apache <= 168.0': [{'age <= 46.0': [{'weight <= 102.9': [{'map_apache <= 137.0': [0, {'weight <= 88.6': [0, 1]}]}, {'heart_rate_apache <= 107.0': [{'glucose_apache <= 87.0': [1, {'heart_rate_apache <= 102.0': [0, {'bmi <= 42.10314543': [1, 0]}]}]}, 0]}]}, {'resprate_apache <= 31.0': [0, {'creatinine_apache <= 3.79': [{'bmi <= 28.02922273': [0, {'glucose_apache <= 53.0': [1, 0]}]}, {'map_apache <= 55.0': [{'age <= 78.0': [1, 0]}, {'glucose_apache <= 149.0': [{'bun_apache <= 29.0': [1, 0]}, {'height <= 180.3': [1, 0]}]}]}]}]}]}, {'resprate_apache <= 32.0': [{'apache_4a_hospital_death_prob <= 0.32': [{'glucose_apache <= 236.0': [{'wbc_apache <= 11.8': [1, {'creatinine_apache <= 0.6': [1, {'bmi <= 30.71907697': [0, 1]}]}]}, {'creatinine_apache <= 1.19': [1, {'hematocrit_apache <= 39.3': [1, {'map_apache <= 52.0': [1, 0]}]}]}]}, {'bun_apache <= 28.0': [{'hematocrit_apache <= 24.4': [1, 0]}, {'age <= 86.0': [{'apache_4a_hospital_death_prob <= 0.48': [1, {'hematocrit_apache <= 32.1': [1, 0]}]}, 0]}]}]}, {'glucose_apache <= 207.0': [{'height <= 178.0': [{'bmi <= 21.60832724': [0, {'wbc_apache <= 15.2': [{'age <= 57.0': [0, 1]}, {'bmi <= 49.609375': [0, 1]}]}]}, 0]}, {'hematocrit_apache <= 43.7': [{'apache_4a_icu_death_prob <= 0.25': [{'hematocrit_apache <= 20.0': [0, 1]}, {'resprate_apache <= 41.0': [{'apache_4a_hospital_death_prob <= 0.79': [1, 0]}, {'map_apache <= 45.0': [1, 0]}]}]}, 1]}]}]}]}\n",
            "{'glucose_apache <= 170.0': [{'age <= 46.0': [0, {'resprate_apache <= 15.0': [{'hematocrit_apache <= 41.1': [{'bmi <= 24.72453641': [{'age <= 60.0': [0, {'sodium_apache <= 134.0': [1, 0]}]}, {'temp_apache <= 36.5': [{'height <= 182.8': [1, 0]}, {'glucose_apache <= 157.0': [0, 1]}]}]}, {'weight <= 100.7': [0, {'bmi <= 32.00171296': [1, 0]}]}]}, {'bmi <= 31.92054927': [0, {'temp_apache <= 36.7': [{'age <= 51.0': [0, {'resprate_apache <= 37.0': [1, 0]}]}, {'hematocrit_apache <= 34.1': [{'age <= 48.0': [0, 1]}, {'heart_rate_apache <= 110.0': [0, 1]}]}]}]}]}]}, {'resprate_apache <= 29.0': [{'heart_rate_apache <= 105.0': [{'heart_rate_apache <= 52.0': [{'sodium_apache <= 129.0': [0, {'glucose_apache <= 246.0': [{'age <= 78.0': [1, 0]}, {'bmi <= 28.94853848': [1, 0]}]}]}, {'resprate_apache <= 24.0': [1, {'bmi <= 50.4551135': [1, 0]}]}]}, {'glucose_apache <= 519.0': [{'glucose_apache <= 215.0': [{'hematocrit_apache <= 21.9': [1, {'bmi <= 24.58477139': [0, 1]}]}, 1]}, {'creatinine_apache <= 0.72': [1, 0]}]}]}, {'glucose_apache <= 221.0': [{'heart_rate_apache <= 47.0': [1, 0]}, {'weight <= 56.7': [{'sodium_apache <= 136.0': [0, 1]}, {'age <= 65.0': [{'age <= 51.0': [1, {'resprate_apache <= 45.0': [1, 0]}]}, {'resprate_apache <= 30.0': [{'heart_rate_apache <= 91.0': [0, 1]}, 1]}]}]}]}]}]}\n",
            "{'glucose_apache <= 161.0': [{'resprate_apache <= 13.0': [{'age <= 47.0': [{'height <= 162.6': [{'weight <= 80.1': [0, 1]}, 0]}, {'creatinine_apache <= 2.0': [{'gcs_verbal_apache <= 2.0': [{'apache_4a_hospital_death_prob <= 0.16': [1, {'wbc_apache <= 9.5': [0, 1]}]}, 0]}, {'hematocrit_apache <= 25.5': [1, {'glucose_apache <= 104.0': [{'glucose_apache <= 86.0': [1, 0]}, 1]}]}]}]}, {'glucose_apache <= 80.0': [{'weight <= 87.09': [{'sodium_apache <= 148.0': [0, {'gcs_verbal_apache <= 3.0': [1, 0]}]}, {'glucose_apache <= 59.0': [1, {'bmi <= 30.00806002': [0, 1]}]}]}, 0]}]}, {'glucose_apache <= 209.0': [{'resprate_apache <= 33.0': [{'bmi <= 21.29065635': [{'hematocrit_apache <= 29.8': [1, 0]}, {'weight <= 72.0': [{'hematocrit_apache <= 35.1': [1, {'gcs_verbal_apache <= 4.0': [0, 1]}]}, {'apache_4a_icu_death_prob <= 0.44': [{'age <= 34.0': [0, 1]}, {'glucose_apache <= 177.0': [1, 0]}]}]}]}, {'gcs_eyes_apache <= 3.0': [1, {'wbc_apache <= 26.2': [0, {'hematocrit_apache <= 28.9': [1, {'age <= 74.0': [0, 1]}]}]}]}]}, {'apache_4a_icu_death_prob <= 0.18': [{'heart_rate_apache <= 156.0': [1, 0]}, {'bun_apache <= 19.0': [0, {'resprate_apache <= 45.0': [{'bun_apache <= 20.0': [0, {'temp_apache <= 37.4': [1, 0]}]}, {'heart_rate_apache <= 168.0': [0, 1]}]}]}]}]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Make predictions with the random forest\n",
        "> Note: Please print the f1-score of the predictions of each decision tree"
      ],
      "metadata": {
        "id": "dZb6EEYnnO05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction_forest(forest, data):\n",
        "  \"\"\"\n",
        "  This function will use the pre-trained random forest to make the predictions\n",
        "  args:\n",
        "  * forest: the random forest\n",
        "  * data: the data used to predict\n",
        "  return:\n",
        "  * y_prediction: the predicted results\n",
        "  \"\"\"\n",
        "  predict_num=len(data)\n",
        "  \n",
        "  y_prediction=[]\n",
        "  tmp=[0]*predict_num\n",
        "  for tre in forest:\n",
        "    a= make_prediction(tre, data)\n",
        "    tmp=np.sum([tmp,a],axis=0).tolist()\n",
        "\n",
        "  tmp=np.around(np.array(tmp)/n_trees)\n",
        "\n",
        "  y_prediction=tmp\n",
        "  \n",
        "\n",
        "  return y_prediction"
      ],
      "metadata": {
        "id": "UbHMZnMDnWpG"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=pd.read_csv('hw2_input_test.csv')\n",
        "\n",
        "y_pred_test = make_prediction_forest(forest, x_test)\n",
        "print(y_pred_test)\n",
        "\n",
        "\n",
        "\n",
        "# score=make_prediction_forest(forest, validx)\n",
        "# sscore=calculate_score(validy,score)\n",
        "# print(sscore)"
      ],
      "metadata": {
        "id": "Hcd70ubwgHq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af715464-b052-4671-d988-a90dda74cc12"
      },
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Write the Output File\n",
        "Save your predictions from the **random forest** in a csv file, named as **hw2_advanced.csv**"
      ],
      "metadata": {
        "id": "2ufa5bP9HveO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced = []\n",
        "for i in range(len(y_pred_test)):\n",
        "  advanced.append(y_pred_test[i])"
      ],
      "metadata": {
        "id": "XdAQcE41JJYB"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_path = 'hw2_advanced.csv'\n",
        "pd.DataFrame(advanced).to_csv(advanced_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "Pq121klSHwWO"
      },
      "execution_count": 387,
      "outputs": []
    }
  ]
}